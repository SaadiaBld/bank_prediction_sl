{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "#from xgboost import XGBRegressor\n",
        "from scipy.stats import randint\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['LoanNr_ChkDgt', 'Name', 'City', 'State', 'Zip', 'Bank', 'BankState',\n",
              "       'NAICS', 'ApprovalDate', 'ApprovalFY', 'Term', 'NoEmp', 'NewExist',\n",
              "       'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'RevLineCr',\n",
              "       'LowDoc', 'ChgOffDate', 'DisbursementDate', 'DisbursementGross',\n",
              "       'BalanceGross', 'MIS_Status', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importer le DataFrame propre depuis le fichier CSV\n",
        "df = pd.read_csv('data.csv')\n",
        "df.head(4)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoanNr_ChkDgt          int64\n",
              "Name                  object\n",
              "City                  object\n",
              "State                 object\n",
              "Zip                    int64\n",
              "Bank                  object\n",
              "BankState             object\n",
              "NAICS                  int64\n",
              "ApprovalDate          object\n",
              "ApprovalFY           float64\n",
              "Term                   int64\n",
              "NoEmp                  int64\n",
              "NewExist               int64\n",
              "CreateJob              int64\n",
              "RetainedJob            int64\n",
              "FranchiseCode          int64\n",
              "UrbanRural             int64\n",
              "RevLineCr             object\n",
              "LowDoc                object\n",
              "ChgOffDate            object\n",
              "DisbursementDate      object\n",
              "DisbursementGross    float64\n",
              "BalanceGross         float64\n",
              "MIS_Status             int64\n",
              "ChgOffPrinGr         float64\n",
              "GrAppv               float64\n",
              "SBA_Appv             float64\n",
              "NAICS_digit           object\n",
              "dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remplacer les valeurs non numériques par 0 et le type des variables\n",
        "df['NewExist'] = df['NewExist'].fillna(0)\n",
        "df['UrbanRural'] = df['UrbanRural'].fillna(0)\n",
        "\n",
        "\n",
        "# Convertir la colonne en type entier\n",
        "df['NewExist'] = df['NewExist'].astype(int)\n",
        "df['NewExist'].astype(int)\n",
        "\n",
        "df['UrbanRural'] = df['UrbanRural'].astype(int)\n",
        "df['UrbanRural'].astype(int)\n",
        "\n",
        "#conserver les deux premiers chiffres de naics\n",
        "df['NAICS_digit'] = df['NAICS'].astype(str).str[:2]\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de lignes : 897167\n",
            "Nombre de colonnes : 28\n"
          ]
        }
      ],
      "source": [
        "#Supprimer les colonnes inutiles\n",
        "#df = df.drop(['ApprovalFY', 'ApprovalDate'], axis=1)\n",
        "\n",
        "#traiter la colonen NAICS pour qu'elle ne contienne que les 2 premiers chiffres des valeurs NAICS\n",
        "#df['NAICS_digit'] = (df['NAICS'] / 10000 ).astype(int)\n",
        "#df = df.drop(['NAICS'], axis=1)\n",
        "df.columns\n",
        "# Utilisez l'attribut shape pour obtenir le nombre de lignes et de colonnes de votre dataframe\n",
        "nombre_lignes, nombre_colonnes = df.shape\n",
        "\n",
        "print(\"Nombre de lignes :\", nombre_lignes)\n",
        "print(\"Nombre de colonnes :\", nombre_colonnes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modélisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "on teste une modélisation avec une imputation des valeurs manquantes, et une en supprimant les valeurs manquantes du df. Selon les résultats, on optera pour l'une ou l'autre du choix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. RandomForest Simple avec SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['LoanNr_ChkDgt', 'Name', 'City', 'State', 'Zip', 'Bank', 'BankState',\n",
              "       'NAICS', 'ApprovalDate', 'ApprovalFY', 'Term', 'NoEmp', 'NewExist',\n",
              "       'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'RevLineCr',\n",
              "       'LowDoc', 'ChgOffDate', 'DisbursementDate', 'DisbursementGross',\n",
              "       'BalanceGross', 'MIS_Status', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv',\n",
              "       'NAICS_digit'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', 'NewExist']\n",
        "num_col = ['NAICS_digit', 'Term' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test RandomForest sans hyperparamètres \n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "# importance des caractéristiques\n",
        "feature_importance = pipeline.named_steps['classifier'].feature_importances_\n",
        "print(\"Importance des caractéristiques :\", feature_importance)\n",
        "\n",
        "print('_____________________')\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print('_____________________')\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('_____________________')\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest Simple\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#on supprime les valeurs manquantes nan de notre df puis on applique une modélisation\n",
        "\n",
        "missing_rows = df.isnull().any(axis=1).sum()\n",
        "missing_rows\n",
        "\n",
        "df_sans_valeurs_manquantes = df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#refait modelisation sur df_sans_valeurs_manquantes sans valeurs manquantes\n",
        "#separer dataset en features et target\n",
        "X = df_sans_valeurs_manquantes.drop('MIS_Status', axis=1)\n",
        "y = df_sans_valeurs_manquantes['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', 'NewExist']\n",
        "num_col = ['NAICS_digit', 'Term' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importance des caractéristiques : [1.21888568e-02 5.62935609e-03 7.35786542e-03 3.13994680e-03\n",
            " 3.13834968e-03 3.36263484e-03 4.61852904e-04 2.70303161e-03\n",
            " 2.88109041e-03 2.55470815e-01 7.03666201e-01]\n",
            "_____________________\n",
            "Score du modèle (train) : 0.9738984054164046\n",
            "Score du modèle (test) : 0.9690739764540502\n",
            "_____________________\n",
            "_____________________\n",
            "Métrique pour le modèle RandomForest Simple sur df sans valeurs manquantes\n",
            "Score d'accuracy 0.9690739764540502\n",
            "Score du recall :  0.9972870320130223\n",
            "Score de la precision :  0.9716299559471365\n",
            "Score F1 :  0.9842913245269547\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.01      0.01       162\n",
            "           1       0.97      1.00      0.98      5529\n",
            "\n",
            "    accuracy                           0.97      5691\n",
            "   macro avg       0.52      0.50      0.50      5691\n",
            "weighted avg       0.95      0.97      0.96      5691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test RandomForest sans hyperparamètres \n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "# importance des caractéristiques\n",
        "feature_importance = pipeline.named_steps['classifier'].feature_importances_\n",
        "print(\"Importance des caractéristiques :\", feature_importance)\n",
        "\n",
        "print('_____________________')\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print('_____________________')\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('_____________________')\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest Simple sur df sans valeurs manquantes\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.Testons KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9467575101958446\n",
            "Score du modèle (test) : 0.927104928776834\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.927104928776834\n",
            "Score du recall :  0.764026402640264\n",
            "Score de la precision :  0.8100942126514132\n",
            "Score F1 :  0.7863862032923961\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     36981\n",
            "           1       0.81      0.76      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.88      0.86      0.87     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test KNNImputer\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle AdaboostClassifierr\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8975565050467521\n",
            "Score du modèle (test) : 0.8926178985030707\n"
          ]
        }
      ],
      "source": [
        "# Tests KNNImputer pour les variables numeriques\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(n_estimators=80, max_depth=40, min_samples_leaf=5, max_features='sqrt'))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8981764808027145\n",
            "Score du modèle (test) : 0.8956508170043915\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.8956508170043915\n",
            "Score du recall :  0.46585427773546584\n",
            "Score de la precision :  0.8858315230509293\n",
            "Score F1 :  0.6105981199567423\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     36981\n",
            "           1       0.89      0.47      0.61      7878\n",
            "\n",
            "    accuracy                           0.90     44859\n",
            "   macro avg       0.89      0.73      0.78     44859\n",
            "weighted avg       0.89      0.90      0.88     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#on joue avec les hyperparametre\n",
        "\n",
        "# Tests KNNImputer pour les variables numeriques\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', IterativeImputer (max_iter=10, random_state=0)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(n_estimators= 80, max_depth=40, min_samples_leaf=5, max_features='sqrt'))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle AdaboostClassifierr\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modélisation \n",
        "\n",
        "#### 1. Randomized search + RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['LoanNr_ChkDgt', 'Name', 'City', 'State', 'Zip', 'Bank', 'BankState',\n",
              "       'NAICS', 'ApprovalDate', 'ApprovalFY', 'Term', 'NoEmp', 'NewExist',\n",
              "       'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'RevLineCr',\n",
              "       'LowDoc', 'ChgOffDate', 'DisbursementDate', 'DisbursementGross',\n",
              "       'BalanceGross', 'MIS_Status', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv',\n",
              "       'NAICS_digit'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['RevLineCr', 'LowDoc', 'FranchiseCode', 'NAICS_digit', 'NewExist', 'UrbanRural' ]\n",
        "num_col = ['Term', 'CreateJob', 'RetainedJob', 'SBA_Appv', 'GrAppv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random search cv\n",
        "hyper_grid = {'classifier__max_depth':list(np.arange(10, 100, step=10)) + [30],\n",
        "              'classifier__n_estimators':[100],\n",
        "              'classifier__max_features':randint(1,7),\n",
        "              'classifier__min_samples_leaf':randint(1,4),\n",
        "              'classifier__min_samples_split':np.arange(2, 10, step=2)\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_cv = RandomizedSearchCV(estimator= pipeline,\n",
        "                               param_distributions=hyper_grid,\n",
        "                               cv = 3,\n",
        "                               n_iter= 9,\n",
        "                               scoring = 'accuracy',\n",
        "                               n_jobs= None,\n",
        "                               return_train_score = True,\n",
        "                               random_state = 42)\n",
        "\n",
        "random_cv.fit(X_train, y_train)\n",
        "\n",
        "# Afficher les meilleurs paramètres\n",
        "print(\"Meilleurs paramètres:\", random_cv.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = random_cv.best_estimator_.score(X_train, y_train)\n",
        "score_te = random_cv.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "\n",
        "# #modele sans randomizedsearchcv\n",
        "# #pipeline.fit(X_train, y_train)\n",
        "\n",
        "# # performance du modèle\n",
        "# score_tr = pipeline.score(X_train, y_train)\n",
        "# score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "# print(\"Score du modèle (train) :\", score_tr)\n",
        "# print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RandomizedSearchCV donne les résultats suivants:\n",
        "Meilleurs paramètres: {'classifier__max_depth': 70, 'classifier__max_features': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 100}\n",
        "Score du modèle (train) : 0.824524119140504\n",
        "Score du modèle (test) : 0.8231104472953844\n",
        "\n",
        "On peut restreindre la recherche d'hyperparamètres à des valeurs proches de ces résultats dans la gridsearchcv.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# on garde la même configuration des X et y.\n",
        "\n",
        "# GridSearchCv\n",
        "params = {'classifier__max_depth': [60, 70, 80],\n",
        "              'classifier__n_estimators':[90, 100, 110],\n",
        "              'classifier__max_features': [3, 4, 5],\n",
        "              'classifier__min_samples_leaf':[1,2],\n",
        "              'classifier__min_samples_split': [5,6,7]\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid = GridSearchCV(pipeline, param_grid = params, scoring = 'accuracy', cv = 4)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Meilleurs paramètres de GridSearch:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = grid.best_estimator_.score(X_train, y_train)\n",
        "score_te = grid.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparamétres du modéle\n",
        "\n",
        "* Random Forest\n",
        "     - max_depth\n",
        "     - min_sample_split\n",
        "     - max_leaf_nodes\n",
        "     - min_samples_leaf\n",
        "     - n_estimators\n",
        "     - max_sample (bootstrap sample)\n",
        "     - max_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# random search cv\n",
        "hyper_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean', 'median'],  # Ajoutez les stratégies d'imputation numérique ici si nécessaire\n",
        "    'classifier_max_depth': list(np.arange(10, 100, step=10)) + [None],\n",
        "    'classifier__n_estimators': np.arange(10, 500, step=50),\n",
        "    'classifier__max_features': randint(1, 7),\n",
        "    'classifier__criterion': ['gini', 'entropy'],\n",
        "    'classifier__min_samples_leaf': randint(1, 4),\n",
        "    'classifier__min_samples_split': np.arange(2, 10, step=2)\n",
        "}\n",
        "\n",
        "# Création du preprocessor pour gérer les deux types de colonnes\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline incluant le prétraitement et le modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])\n",
        "\n",
        "random_cv = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=hyper_grid,\n",
        "    cv=3,\n",
        "    n_iter=5,\n",
        "    scoring='accuracy',  # ou une autre métrique que vous souhaitez évaluer\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit du RandomizedSearchCV\n",
        "random_cv.fit(X_train, y_train)\n",
        "\n",
        "# Afficher les meilleurs paramètres\n",
        "print(\"Meilleurs paramètres:\", random_cv.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = random_cv.best_estimator_.score(X_train, y_train)\n",
        "score_te = random_cv.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#adaboost\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "\n",
        "#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify=y)\n",
        "\n",
        "cat_col = ['RevLineCr', 'LowDoc', 'FranchiseCode' ]\n",
        "num_col = ['NAICS_digit', 'Term', 'NewExist', 'UrbanRural']\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8935711189547341\n",
            "Score du modèle (test) : 0.894044606930682\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.894044606930682\n",
            "Score du recall :  0.5917454316320101\n",
            "Score de la precision :  0.7562409405701401\n",
            "Score F1 :  0.663956447963801\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94     73847\n",
            "           1       0.76      0.59      0.66     15870\n",
            "\n",
            "    accuracy                           0.89     89717\n",
            "   macro avg       0.84      0.78      0.80     89717\n",
            "weighted avg       0.89      0.89      0.89     89717\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', AdaBoostClassifier())])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle AdaboostClassifierr\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.930283418670246\n",
            "Score du modèle (test) : 0.9302035266055864\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.9302035266055864\n",
            "Score du recall :  0.765041888804265\n",
            "Score de la precision :  0.8248255097851376\n",
            "Score F1 :  0.793809680605861\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96     36981\n",
            "           1       0.82      0.77      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.89      0.87      0.88     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'distance')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle XGBoost\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', XGBClassifier(random_state=42))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rappel de l'encodage pour la variable MIS_Status: {'P I F': 0, 'CHGOFF': 1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Term               int64\n",
              "FranchiseCode      int64\n",
              "UrbanRural         int64\n",
              "RevLineCr         object\n",
              "LowDoc            object\n",
              "MIS_Status         int64\n",
              "GrAppv           float64\n",
              "SBA_Appv         float64\n",
              "NAICS_digit       object\n",
              "dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cat = df.drop(['LoanNr_ChkDgt', 'Name','NAICS', 'City', 'State', 'Zip', 'Bank', 'BankState', 'ApprovalDate', 'ApprovalFY', 'NoEmp', 'CreateJob', 'RetainedJob', 'ChgOffDate', 'DisbursementDate', 'DisbursementGross', 'BalanceGross', 'ChgOffPrinGr', 'NewExist'], axis=1)\n",
        "df_cat.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#separer dataset en features et target\n",
        "X = df_cat.drop('MIS_Status', axis=1)\n",
        "y = df_cat['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural']\n",
        "num_col = ['NAICS_digit', 'Term', 'SBA_Appv', 'GrAppv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 40) (1511283832.py, line 40)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 40\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('importance des features: feature_importance)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 40)\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 2, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle CatBoost\n",
        "modelcat = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', CatBoostClassifier(random_state=42, verbose=False))])\n",
        "\n",
        "modelcat.fit(X_train, y_train)\n",
        "\n",
        "y_pred = modelcat.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = modelcat.score(X_train, y_train)\n",
        "score_te = modelcat.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#extrait classifieur de la pipeline\n",
        "catboost_classifier = modelcat.named_steps['classifier']\n",
        "#feature importance\n",
        "feature_importance = catboost_classifier.get_importance(prettified=True)\n",
        "print('importance des features: feature_importance)\n",
        "#feature_importance = pipeline.named_steps['classifier'].get_feature_importance()\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noms des variables : ['RevLineCr_Y', 'LowDoc_Y', 'FranchiseCode_1', 'UrbanRural_0', 'UrbanRural_1', 'UrbanRural_2', 'NewExist_0', 'NewExist_1', 'NewExist_2', 'NAICS_digit', 'Term', 'SBA_Appv', 'GrAppv']\n"
          ]
        }
      ],
      "source": [
        "# Obtenez les noms de colonnes transformées\n",
        "preprocessed_cat_columns = modelcat.named_steps['preprocessor'].transformers_[0][1]['onehot'].get_feature_names_out(input_features=cat_col)\n",
        "preprocessed_columns = list(preprocessed_cat_columns) + num_col\n",
        "\n",
        "print('Noms des variables :', preprocessed_columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9407315195915091\n",
            "Score du modèle (test) : 0.9381840879199269\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.9381840879199269\n",
            "Score du recall :  0.8010916476263011\n",
            "Score de la precision :  0.8395636557137156\n",
            "Score F1 :  0.8198765833062682\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     36981\n",
            "           1       0.84      0.80      0.82      7878\n",
            "\n",
            "    accuracy                           0.94     44859\n",
            "   macro avg       0.90      0.88      0.89     44859\n",
            "weighted avg       0.94      0.94      0.94     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 2, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle CatBoost\n",
        "modelcat = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', CatBoostClassifier(random_state=42, verbose=False))])\n",
        "\n",
        "modelcat.fit(X_train, y_train)\n",
        "\n",
        "y_pred = modelcat.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = modelcat.score(X_train, y_train)\n",
        "score_te = modelcat.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# #extrait classifieur de la pipeline\n",
        "# catboost_classifier = modelcat.named_steps['classifier']\n",
        "# #feature importance\n",
        "# feature_importance = catboost_classifier.get_feature_importance(prettified=True)\n",
        "# print('importance des features:', feature_importance)\n",
        "# #feature_importance = pipeline.named_steps['classifier'].get_feature_importance()\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#le modele catboost est le plus performant pour l'instant, on le charge sous forme d'un fichier pkl\n",
        "import pickle\n",
        "\n",
        "pickle.dump(modelcat, open('modelcatb.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>MIS_Status</th>\n",
              "      <th>GrAppv</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>NAICS_digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>287000.0</td>\n",
              "      <td>215250.0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>240</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>229000.0</td>\n",
              "      <td>229000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Term  FranchiseCode  UrbanRural RevLineCr LowDoc  MIS_Status    GrAppv  \\\n",
              "0    84              0           0         N      Y           0   60000.0   \n",
              "1    60              0           0         N      Y           0   40000.0   \n",
              "2   180              0           0         N      N           0  287000.0   \n",
              "3    60              0           0         N      Y           0   35000.0   \n",
              "4   240              0           0         N      N           0  229000.0   \n",
              "\n",
              "   SBA_Appv NAICS_digit  \n",
              "0   48000.0          45  \n",
              "1   32000.0          72  \n",
              "2  215250.0          62  \n",
              "3   28000.0           0  \n",
              "4  229000.0           0  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cat.columns\n",
        "df_cat.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Term  FranchiseCode  UrbanRural RevLineCr LowDoc    GrAppv  SBA_Appv  \\\n",
            "0         84              0           0         N      Y   60000.0   48000.0   \n",
            "1         60              0           0         N      Y   40000.0   32000.0   \n",
            "2        180              0           0         N      N  287000.0  215250.0   \n",
            "3         60              0           0         N      Y   35000.0   28000.0   \n",
            "4        240              0           0         N      N  229000.0  229000.0   \n",
            "...      ...            ...         ...       ...    ...       ...       ...   \n",
            "897162    60              0           0       NaN      N   70000.0   56000.0   \n",
            "897163    60              0           0         Y      N   85000.0   42500.0   \n",
            "897164   108              0           0         N      N  300000.0  225000.0   \n",
            "897165    60              0           0         N      Y   75000.0   60000.0   \n",
            "897166    48              0           0         N      N   30000.0   24000.0   \n",
            "\n",
            "       NAICS_digit  \n",
            "0               45  \n",
            "1               72  \n",
            "2               62  \n",
            "3                0  \n",
            "4                0  \n",
            "...            ...  \n",
            "897162          45  \n",
            "897163          45  \n",
            "897164          33  \n",
            "897165           0  \n",
            "897166           0  \n",
            "\n",
            "[897167 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# values = {'Term':(120,100), 'FranchiseCode': (0,1), 'UrbanRural': (0,0), 'RevLineCr': ('N','Y'), 'LowDoc': ('Y','N'), 'GrAppv': (48000, 28000), 'SBA_Appv':(20000,60000), 'NAICS_digit':(45,62)}\n",
        "# pred = modelcat.predict(values)\n",
        "\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict_loan(model,data):\n",
        "    # Convertir la liste de listes en DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Term', 'FranchiseCode', 'UrbanRural', 'RevLineCr', 'LowDoc', 'GrAppv', 'SBA_Appv', 'NAICS_digit'])\n",
        "    predictions = model.predict(df)\n",
        "    return predictions[0]\n",
        "\n",
        "predict_loan(modelcat,[[84, 0, 0, 'N', 'Y',60000.0, 48000.0, 45]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "897162    0\n",
              "897163    0\n",
              "897164    0\n",
              "897165    1\n",
              "897166    0\n",
              "Name: MIS_Status, Length: 897167, dtype: int64"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(y[897166])\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stacking/Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
