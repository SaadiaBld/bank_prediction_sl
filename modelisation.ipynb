{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Zip                   0\n",
              "Bank               1506\n",
              "NAICS                 0\n",
              "Term                  0\n",
              "NewExist           1162\n",
              "CreateJob             0\n",
              "RetainedJob           0\n",
              "FranchiseCode         0\n",
              "UrbanRural       322826\n",
              "RevLineCr        277255\n",
              "LowDoc           277255\n",
              "MIS_Status            0\n",
              "SBA_Appv              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importer le DataFrame propre depuis le fichier CSV\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zip</th>\n",
              "      <th>NAICS</th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>CreateJob</th>\n",
              "      <th>RetainedJob</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>MIS_Status</th>\n",
              "      <th>SBA_Appv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47711</td>\n",
              "      <td>451120</td>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>48000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46526</td>\n",
              "      <td>722410</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>32000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47401</td>\n",
              "      <td>621210</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>215250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74012</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>28000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32801</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>229000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897162</th>\n",
              "      <td>43221</td>\n",
              "      <td>451120</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>56000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897163</th>\n",
              "      <td>43221</td>\n",
              "      <td>451130</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897164</th>\n",
              "      <td>93455</td>\n",
              "      <td>332321</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897165</th>\n",
              "      <td>96830</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>60000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897166</th>\n",
              "      <td>96734</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>24000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897167 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Zip   NAICS  Term  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
              "0       47711  451120    84         2          0            0              0   \n",
              "1       46526  722410    60         2          0            0              0   \n",
              "2       47401  621210   180         1          0            0              0   \n",
              "3       74012       0    60         1          0            0              0   \n",
              "4       32801       0   240         1          7            7              0   \n",
              "...       ...     ...   ...       ...        ...          ...            ...   \n",
              "897162  43221  451120    60         1          0            0              0   \n",
              "897163  43221  451130    60         1          0            0              0   \n",
              "897164  93455  332321   108         1          0            0              0   \n",
              "897165  96830       0    60         1          0            0              0   \n",
              "897166  96734       0    48         2          0            0              0   \n",
              "\n",
              "        UrbanRural RevLineCr LowDoc  MIS_Status  SBA_Appv  \n",
              "0                0         N      N           0   48000.0  \n",
              "1                0         N      N           0   32000.0  \n",
              "2                0         N      N           0  215250.0  \n",
              "3                0         N      N           0   28000.0  \n",
              "4                0         N      N           0  229000.0  \n",
              "...            ...       ...    ...         ...       ...  \n",
              "897162           0       NaN    NaN           0   56000.0  \n",
              "897163           0         Y      Y           0   42500.0  \n",
              "897164           0         N      N           0  225000.0  \n",
              "897165           0         N      N           1   60000.0  \n",
              "897166           0         N      N           0   24000.0  \n",
              "\n",
              "[897167 rows x 12 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remplacer les valeurs non numériques par 0 et le type des variables\n",
        "df['NewExist'] = df['NewExist'].fillna(0)\n",
        "df['UrbanRural'] = df['UrbanRural'].fillna(0)\n",
        "\n",
        "\n",
        "# Convertir la colonne en type entier\n",
        "df['NewExist'] = df['NewExist'].astype(int)\n",
        "df['NewExist'].astype(int)\n",
        "\n",
        "df['UrbanRural'] = df['UrbanRural'].astype(int)\n",
        "df['UrbanRural'].astype(int)\n",
        "\n",
        "# supprimer la colonne 'bank' trop complexifiante ? \n",
        "df = df.drop(['Bank' ], axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>MIS_Status</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>NAICS_digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Term  NewExist  FranchiseCode  UrbanRural RevLineCr LowDoc  MIS_Status  \\\n",
              "0    84         2              0           0         N      N           0   \n",
              "1    60         2              0           0         N      N           0   \n",
              "\n",
              "   SBA_Appv  NAICS_digit  \n",
              "0   48000.0           45  \n",
              "1   32000.0           72  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#traiter la colonen NAICS pour qu'elle ne contienne que les 2 premiers chiffres des valeurs NAICS\n",
        "df['NAICS_digit'] = (df['NAICS'] / 10000 ).astype(int)\n",
        "df = df.drop(['NAICS'], axis=1)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modélisation\n",
        "\n",
        "##### 1. Regression logistique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Séparation des caractéristiques et de la cible\n",
        "X = df.drop(columns=['MIS_Status'])\n",
        "y = df['MIS_Status']\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Définition des colonnes catégorielles et numériques\n",
        "cat_cols = ['RevLineCr', 'LowDoc']\n",
        "num_cols = ['Zip', 'NAICS_digit', 'Term', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'SBA_Appv']\n",
        "\n",
        "# Création des transformateurs pour les colonnes catégorielles et numériques\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Prétraitement des données avec ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_cols),\n",
        "        ('num', num_transformer, num_cols)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline avec régression logistique\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Entraînement du modèle\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prédiction sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. RandomForest sans hyperparamètres + SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Term', 'NewExist', 'FranchiseCode', 'UrbanRural', 'RevLineCr',\n",
              "       'LowDoc', 'MIS_Status', 'SBA_Appv', 'NAICS_digit'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['CreateJob', 'RetainedJob', 'Zip'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreateJob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetainedJob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['CreateJob', 'RetainedJob', 'Zip'] not found in axis\""
          ]
        }
      ],
      "source": [
        "df = df.drop(['CreateJob', 'RetainedJob', 'Zip'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>NAICS_digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>215250.0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>229000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897162</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897163</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>42500.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897164</th>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897165</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897166</th>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897167 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Term  NewExist  FranchiseCode  UrbanRural RevLineCr LowDoc  SBA_Appv  \\\n",
              "0         84         2              0           0         N      N   48000.0   \n",
              "1         60         2              0           0         N      N   32000.0   \n",
              "2        180         1              0           0         N      N  215250.0   \n",
              "3         60         1              0           0         N      N   28000.0   \n",
              "4        240         1              0           0         N      N  229000.0   \n",
              "...      ...       ...            ...         ...       ...    ...       ...   \n",
              "897162    60         1              0           0       NaN    NaN   56000.0   \n",
              "897163    60         1              0           0         Y      Y   42500.0   \n",
              "897164   108         1              0           0         N      N  225000.0   \n",
              "897165    60         1              0           0         N      N   60000.0   \n",
              "897166    48         2              0           0         N      N   24000.0   \n",
              "\n",
              "        NAICS_digit  \n",
              "0                45  \n",
              "1                72  \n",
              "2                62  \n",
              "3                 0  \n",
              "4                 0  \n",
              "...             ...  \n",
              "897162           45  \n",
              "897163           45  \n",
              "897164           33  \n",
              "897165            0  \n",
              "897166            0  \n",
              "\n",
              "[897167 rows x 8 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop(['MIS_Status'], axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'NewExist','RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural']\n",
        "num_col = ['Term', 'SBA_Appv' ]\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Term: 0.009092005422919016\n",
            "NewExist: 0.0013369959023449979\n",
            "FranchiseCode: 0.0005226630111282156\n",
            "UrbanRural: 0.00019449096181287022\n",
            "RevLineCr: 0.0017450560682858386\n",
            "LowDoc: 0.00097106039127088\n",
            "MIS_Status: 0.0010655448438308876\n",
            "SBA_Appv: 0.0017110076739835609\n",
            "NAICS_digit: 0.0017400070724943074\n",
            "_____________________\n",
            "Score du modèle (train) : 0.9565661709147397\n",
            "Score du modèle (test) : 0.9277068146860162\n",
            "_____________________\n",
            "_____________________\n",
            "Métrique pour le modèle RandomForest Simple\n",
            "Score d'accuracy 0.9277068146860162\n",
            "Score du recall :  0.7538715410002539\n",
            "Score de la precision :  0.8199641032721248\n",
            "Score F1 :  0.7855300575358772\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     36981\n",
            "           1       0.82      0.75      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.88      0.86      0.87     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test RandomForest sans hyperparamètres \n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(max_depth=50, n_estimators=150, min_samples_split=10))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "# Accéder à l'importance des caractéristiques\n",
        "feature_importance = pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# Associer les importances aux noms des caractéristiques\n",
        "feature_importance_dict = dict(zip(df.columns, feature_importance))\n",
        "\n",
        "# Afficher les noms des caractéristiques et leurs importances\n",
        "for feature, importance in feature_importance_dict.items():\n",
        "    print(f\"{feature}: {importance}\")\n",
        "\n",
        "print('_____________________')\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print('_____________________')\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('_____________________')\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest Simple\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/saadia/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/Users/saadia/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8221370678205532\n",
            "Score du modèle (test) : 0.8151318575982524\n",
            "Métrique pour le modèle RandomForest+KNNImputer\n",
            "Score d'accuracy 0.8151318575982524\n",
            "Score du recall :  0.7580604214267581\n",
            "Score de la precision :  0.4832106157456105\n",
            "Score F1 :  0.5902060582102091\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88     36981\n",
            "           1       0.48      0.76      0.59      7878\n",
            "\n",
            "    accuracy                           0.82     44859\n",
            "   macro avg       0.71      0.79      0.74     44859\n",
            "weighted avg       0.86      0.82      0.83     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rfk = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(class_weight='balanced',\n",
        "                                                                 max_depth=60,\n",
        "                                                                 min_samples_split=4,\n",
        "                                                                 n_estimators=110\n",
        "                                                                 ))])\n",
        "\n",
        "model_rfk.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_rfk.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rfk.score(X_train, y_train)\n",
        "score_te = model_rfk.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest+KNNImputer\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Accéder aux importances des caractéristiques à partir du modèle RandomForest entraîné\n",
        "feature_importance = model_rfk.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# Obtenir les noms des caractéristiques après la transformation\n",
        "cat_encoder = model_rfk.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
        "feature_names = list(cat_encoder.get_feature_names_out(cat_col)) + num_col\n",
        "\n",
        "# Associer les importances aux noms des caractéristiques\n",
        "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
        "\n",
        "# Afficher les importances des caractéristiques\n",
        "for feature, importance in feature_importance_dict.items():\n",
        "    print(f\"{feature}: {importance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### * Hyperparamétres du modéle combiné au KNNImputer\n",
        "\n",
        "* Random Forest\n",
        "     - max_depth\n",
        "     - min_sample_split\n",
        "     - max_leaf_nodes\n",
        "     - min_samples_leaf\n",
        "     - n_estimators\n",
        "     - max_sample (bootstrap sample)\n",
        "     - max_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9184379355819727\n",
            "Score du modèle (test) : 0.9015136316012394\n",
            "Métrique pour le modèle RandomForest+KNNImputer\n",
            "Score d'accuracy 0.9277068146860162\n",
            "Score du recall :  0.7538715410002539\n",
            "Score de la precision :  0.8199641032721248\n",
            "Score F1 :  0.7855300575358772\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     36981\n",
            "           1       0.82      0.75      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.88      0.86      0.87     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rfkp = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(class_weight='balanced', n_estimators=170, max_depth=50, min_samples_leaf=5, max_features='sqrt'))])\n",
        "\n",
        "model_rfkp.fit(X_train, y_train)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rfkp.score(X_train, y_train)\n",
        "score_te = model_rfkp.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest+KNNImputer\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.Iterative Imputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8981764808027145\n",
            "Score du modèle (test) : 0.8956508170043915\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.8956508170043915\n",
            "Score du recall :  0.46585427773546584\n",
            "Score de la precision :  0.8858315230509293\n",
            "Score F1 :  0.6105981199567423\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     36981\n",
            "           1       0.89      0.47      0.61      7878\n",
            "\n",
            "    accuracy                           0.90     44859\n",
            "   macro avg       0.89      0.73      0.78     44859\n",
            "weighted avg       0.89      0.90      0.88     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#on conserve les meme hyperparamètres du RandomForest précédent mais on change la méthode d'imputation avec iterative imputer\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', IterativeImputer (max_iter=20, random_state=0)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(n_estimators= 150, max_depth=45, min_samples_leaf=6, max_features='sqrt'))])\n",
        "\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rf.score(X_train, y_train)\n",
        "score_te = model_rf.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le RandomForestClassifieur avec hyperparamètres:\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modélisation \n",
        "\n",
        "#### 1. Randomized search + RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'Zip', 'NewExist','CreateJob', 'RetainedJob', 'RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', ]\n",
        "num_col = ['Term', 'SBA_Appv' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'distance')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random search cv\n",
        "hyper_grid = {'classifier__max_depth':list(np.arange(60, 100, step=10)) + [30],\n",
        "              'classifier__n_estimators':[100],\n",
        "              'classifier__max_features':randint(1,7),\n",
        "              'classifier__min_samples_leaf':randint(1,4),\n",
        "              'classifier__min_samples_split':np.arange(2, 10, step=2)\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rdmz_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_cv = RandomizedSearchCV(estimator= pipeline,\n",
        "                               param_distributions=hyper_grid,\n",
        "                               cv = 3,\n",
        "                               n_iter= 9,\n",
        "                               scoring = 'accuracy',\n",
        "                               n_jobs= None,\n",
        "                               return_train_score = True,\n",
        "                               random_state = 42)\n",
        "\n",
        "random_cv.fit(X_train, y_train)\n",
        "y_pred = model_rdmz_rf.predict(X_test)\n",
        "\n",
        "# Les meilleurs paramètres\n",
        "print(\"Meilleurs paramètres:\", random_cv.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = random_cv.best_estimator_.score(X_train, y_train)\n",
        "score_te = random_cv.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RandomizedSearchCV donne les résultats suivants:\n",
        "Meilleurs paramètres: {'classifier__max_depth': 70, 'classifier__max_features': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 100}\n",
        "Score du modèle (train) : 0.824524119140504\n",
        "Score du modèle (test) : 0.8231104472953844\n",
        "\n",
        "On peut restreindre la recherche d'hyperparamètres à des valeurs proches de ces résultats dans la gridsearchcv.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. GridSearch sur les hyperparamètres du RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GridSearchCv\n",
        "params = {'classifier__max_depth': [60, 70, 80],\n",
        "              'classifier__n_estimators':[90, 100, 110],\n",
        "              'classifier__max_features': [3, 4, 5],\n",
        "              'classifier__min_samples_leaf':[1,2],\n",
        "              'classifier__min_samples_split': [5,6,7]\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid = GridSearchCV(pipeline, param_grid = params, scoring = 'accuracy', cv = 4)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Meilleurs paramètres de GridSearch:\", grid.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = grid.best_estimator_.score(X_train, y_train)\n",
        "score_te = grid.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La gridsearch a été interrompue malheureusement car elle a nécéssité énormément de ressources informatiques pour etre calculée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "'''#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'Zip', 'NewExist','CreateJob', 'RetainedJob', 'RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', ]\n",
        "num_col = ['Term', 'SBA_Appv' ]'''\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights='distance')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8527363347522258\n",
            "Score du modèle (test) : 0.851668561492677\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.851668561492677\n",
            "Score du recall :  0.8717948717948718\n",
            "Score de la precision :  0.5489130434782609\n",
            "Score F1 :  0.6736635605689063\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.90     36981\n",
            "           1       0.55      0.87      0.67      7878\n",
            "\n",
            "    accuracy                           0.85     44859\n",
            "   macro avg       0.76      0.86      0.79     44859\n",
            "weighted avg       0.90      0.85      0.86     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', AdaBoostClassifier())])\n",
        "\n",
        "sample_weights = compute_sample_weight(class_weight ='balanced', y= y_train)\n",
        "\n",
        "pipeline.fit(X_train, y_train, classifier__sample_weight = sample_weights)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle AdaboostClassifierr\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9032169121960606\n",
            "Score du modèle (test) : 0.8999086025100872\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.8999086025100872\n",
            "Score du recall :  0.900990099009901\n",
            "Score de la precision :  0.6567357512953368\n",
            "Score F1 :  0.7597131542331158\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94     36981\n",
            "           1       0.66      0.90      0.76      7878\n",
            "\n",
            "    accuracy                           0.90     44859\n",
            "   macro avg       0.82      0.90      0.85     44859\n",
            "weighted avg       0.92      0.90      0.91     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "weight_ratio = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy = 'median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle XGBoost\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', XGBClassifier(scale_pos_weight=weight_ratio, random_state=42))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rappel de l'encodage pour la variable MIS_Status: {'P I F': 0, 'CHGOFF': 1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy = 'mean')),\n",
        "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle CatBoost\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', CatBoostClassifier(random_state=42))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stacking/Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sauvegarder le modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparamétres du modéle\n",
        "\n",
        "* Random Forest\n",
        "     - max_depth\n",
        "     - min_sample_split\n",
        "     - max_leaf_nodes\n",
        "     - min_samples_leaf\n",
        "     - n_estimators\n",
        "     - max_sample (bootstrap sample)\n",
        "     - max_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour sauvegarder le pipeline dans un fichier pickle après l'avoir entraîné et évalué, il faut suivre les étapes suivantes :\n",
        "\n",
        "    Importer le module pickle.\n",
        "\n",
        "    Utiliser la fonction dump de pickle pour enregistrer votre pipeline dans un fichier pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "#enregistrer le modéle ici 'pipeline' dans un fichier pickle\n",
        "\n",
        "with open('pipeline_rf.pickle', 'wb') as f:\n",
        "    pickle.dump(pipeline, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'mon fichier'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
