{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Zip                   0\n",
              "Bank               1506\n",
              "NAICS                 0\n",
              "Term                  0\n",
              "NewExist           1162\n",
              "CreateJob             0\n",
              "RetainedJob           0\n",
              "FranchiseCode         0\n",
              "UrbanRural       322826\n",
              "RevLineCr        277255\n",
              "LowDoc           277255\n",
              "MIS_Status            0\n",
              "SBA_Appv              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importer le DataFrame propre depuis le fichier CSV\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zip</th>\n",
              "      <th>NAICS</th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>CreateJob</th>\n",
              "      <th>RetainedJob</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>MIS_Status</th>\n",
              "      <th>SBA_Appv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47711</td>\n",
              "      <td>451120</td>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>48000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46526</td>\n",
              "      <td>722410</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>32000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47401</td>\n",
              "      <td>621210</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>215250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74012</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>28000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32801</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>229000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897162</th>\n",
              "      <td>43221</td>\n",
              "      <td>451120</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>56000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897163</th>\n",
              "      <td>43221</td>\n",
              "      <td>451130</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897164</th>\n",
              "      <td>93455</td>\n",
              "      <td>332321</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897165</th>\n",
              "      <td>96830</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>60000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897166</th>\n",
              "      <td>96734</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>24000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897167 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Zip   NAICS  Term  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
              "0       47711  451120    84         2          0            0              0   \n",
              "1       46526  722410    60         2          0            0              0   \n",
              "2       47401  621210   180         1          0            0              0   \n",
              "3       74012       0    60         1          0            0              0   \n",
              "4       32801       0   240         1          7            7              0   \n",
              "...       ...     ...   ...       ...        ...          ...            ...   \n",
              "897162  43221  451120    60         1          0            0              0   \n",
              "897163  43221  451130    60         1          0            0              0   \n",
              "897164  93455  332321   108         1          0            0              0   \n",
              "897165  96830       0    60         1          0            0              0   \n",
              "897166  96734       0    48         2          0            0              0   \n",
              "\n",
              "        UrbanRural RevLineCr LowDoc  MIS_Status  SBA_Appv  \n",
              "0                0         N      N           0   48000.0  \n",
              "1                0         N      N           0   32000.0  \n",
              "2                0         N      N           0  215250.0  \n",
              "3                0         N      N           0   28000.0  \n",
              "4                0         N      N           0  229000.0  \n",
              "...            ...       ...    ...         ...       ...  \n",
              "897162           0       NaN    NaN           0   56000.0  \n",
              "897163           0         Y      Y           0   42500.0  \n",
              "897164           0         N      N           0  225000.0  \n",
              "897165           0         N      N           1   60000.0  \n",
              "897166           0         N      N           0   24000.0  \n",
              "\n",
              "[897167 rows x 12 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remplacer les valeurs non numériques par 0 et le type des variables\n",
        "df['NewExist'] = df['NewExist'].fillna(0)\n",
        "df['UrbanRural'] = df['UrbanRural'].fillna(0)\n",
        "\n",
        "\n",
        "# Convertir la colonne en type entier\n",
        "df['NewExist'] = df['NewExist'].astype(int)\n",
        "df['NewExist'].astype(int)\n",
        "\n",
        "df['UrbanRural'] = df['UrbanRural'].astype(int)\n",
        "df['UrbanRural'].astype(int)\n",
        "\n",
        "# supprimer la colonne 'bank' trop complexifiante ? \n",
        "df = df.drop(['Bank' ], axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>MIS_Status</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>NAICS_digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Term  NewExist  FranchiseCode  UrbanRural RevLineCr LowDoc  MIS_Status  \\\n",
              "0    84         2              0           0         N      N           0   \n",
              "1    60         2              0           0         N      N           0   \n",
              "\n",
              "   SBA_Appv  NAICS_digit  \n",
              "0   48000.0           45  \n",
              "1   32000.0           72  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#traiter la colonen NAICS pour qu'elle ne contienne que les 2 premiers chiffres des valeurs NAICS\n",
        "df['NAICS_digit'] = (df['NAICS'] / 10000 ).astype(int)\n",
        "df = df.drop(['NAICS'], axis=1)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modélisation\n",
        "\n",
        "##### 1. Regression logistique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Séparation des caractéristiques et de la cible\n",
        "X = df.drop(columns=['MIS_Status'])\n",
        "y = df['MIS_Status']\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Définition des colonnes catégorielles et numériques\n",
        "cat_cols = ['RevLineCr', 'LowDoc']\n",
        "num_cols = ['Zip', 'NAICS_digit', 'Term', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'SBA_Appv']\n",
        "\n",
        "# Création des transformateurs pour les colonnes catégorielles et numériques\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Prétraitement des données avec ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_cols),\n",
        "        ('num', num_transformer, num_cols)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline avec régression logistique\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Entraînement du modèle\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prédiction sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. RandomForest sans hyperparamètres + SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Term', 'NewExist', 'FranchiseCode', 'UrbanRural', 'RevLineCr',\n",
              "       'LowDoc', 'MIS_Status', 'SBA_Appv', 'NAICS_digit'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['CreateJob', 'RetainedJob', 'Zip'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreateJob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetainedJob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['CreateJob', 'RetainedJob', 'Zip'] not found in axis\""
          ]
        }
      ],
      "source": [
        "df = df.drop(['CreateJob', 'RetainedJob', 'Zip'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>UrbanRural</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>NAICS_digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>215250.0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>229000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897162</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56000.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897163</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>42500.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897164</th>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897165</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897166</th>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897167 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Term  NewExist  FranchiseCode  UrbanRural RevLineCr LowDoc  SBA_Appv  \\\n",
              "0         84         2              0           0         N      N   48000.0   \n",
              "1         60         2              0           0         N      N   32000.0   \n",
              "2        180         1              0           0         N      N  215250.0   \n",
              "3         60         1              0           0         N      N   28000.0   \n",
              "4        240         1              0           0         N      N  229000.0   \n",
              "...      ...       ...            ...         ...       ...    ...       ...   \n",
              "897162    60         1              0           0       NaN    NaN   56000.0   \n",
              "897163    60         1              0           0         Y      Y   42500.0   \n",
              "897164   108         1              0           0         N      N  225000.0   \n",
              "897165    60         1              0           0         N      N   60000.0   \n",
              "897166    48         2              0           0         N      N   24000.0   \n",
              "\n",
              "        NAICS_digit  \n",
              "0                45  \n",
              "1                72  \n",
              "2                62  \n",
              "3                 0  \n",
              "4                 0  \n",
              "...             ...  \n",
              "897162           45  \n",
              "897163           45  \n",
              "897164           33  \n",
              "897165            0  \n",
              "897166            0  \n",
              "\n",
              "[897167 rows x 8 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop(['MIS_Status'], axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'NewExist','RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural']\n",
        "num_col = ['Term', 'SBA_Appv' ]\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Term: 0.009092005422919016\n",
            "NewExist: 0.0013369959023449979\n",
            "FranchiseCode: 0.0005226630111282156\n",
            "UrbanRural: 0.00019449096181287022\n",
            "RevLineCr: 0.0017450560682858386\n",
            "LowDoc: 0.00097106039127088\n",
            "MIS_Status: 0.0010655448438308876\n",
            "SBA_Appv: 0.0017110076739835609\n",
            "NAICS_digit: 0.0017400070724943074\n",
            "_____________________\n",
            "Score du modèle (train) : 0.9565661709147397\n",
            "Score du modèle (test) : 0.9277068146860162\n",
            "_____________________\n",
            "_____________________\n",
            "Métrique pour le modèle RandomForest Simple\n",
            "Score d'accuracy 0.9277068146860162\n",
            "Score du recall :  0.7538715410002539\n",
            "Score de la precision :  0.8199641032721248\n",
            "Score F1 :  0.7855300575358772\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     36981\n",
            "           1       0.82      0.75      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.88      0.86      0.87     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test RandomForest sans hyperparamètres \n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(max_depth=50, n_estimators=150, min_samples_split=10))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "# Accéder à l'importance des caractéristiques\n",
        "feature_importance = pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# Associer les importances aux noms des caractéristiques\n",
        "feature_importance_dict = dict(zip(df.columns, feature_importance))\n",
        "\n",
        "# Afficher les noms des caractéristiques et leurs importances\n",
        "for feature, importance in feature_importance_dict.items():\n",
        "    print(f\"{feature}: {importance}\")\n",
        "\n",
        "print('_____________________')\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print('_____________________')\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('_____________________')\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest Simple\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/saadia/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/Users/saadia/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8221370678205532\n",
            "Score du modèle (test) : 0.8151318575982524\n",
            "Métrique pour le modèle RandomForest+KNNImputer\n",
            "Score d'accuracy 0.8151318575982524\n",
            "Score du recall :  0.7580604214267581\n",
            "Score de la precision :  0.4832106157456105\n",
            "Score F1 :  0.5902060582102091\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88     36981\n",
            "           1       0.48      0.76      0.59      7878\n",
            "\n",
            "    accuracy                           0.82     44859\n",
            "   macro avg       0.71      0.79      0.74     44859\n",
            "weighted avg       0.86      0.82      0.83     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rfk = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(class_weight='balanced',\n",
        "                                                                 max_depth=60,\n",
        "                                                                 min_samples_split=4,\n",
        "                                                                 n_estimators=110\n",
        "                                                                 ))])\n",
        "\n",
        "model_rfk.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_rfk.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rfk.score(X_train, y_train)\n",
        "score_te = model_rfk.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest+KNNImputer\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Accéder aux importances des caractéristiques à partir du modèle RandomForest entraîné\n",
        "feature_importance = model_rfk.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# Obtenir les noms des caractéristiques après la transformation\n",
        "cat_encoder = model_rfk.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
        "feature_names = list(cat_encoder.get_feature_names_out(cat_col)) + num_col\n",
        "\n",
        "# Associer les importances aux noms des caractéristiques\n",
        "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
        "\n",
        "# Afficher les importances des caractéristiques\n",
        "for feature, importance in feature_importance_dict.items():\n",
        "    print(f\"{feature}: {importance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### * Hyperparamétres du modéle combiné au KNNImputer\n",
        "\n",
        "* Random Forest\n",
        "     - max_depth\n",
        "     - min_sample_split\n",
        "     - max_leaf_nodes\n",
        "     - min_samples_leaf\n",
        "     - n_estimators\n",
        "     - max_sample (bootstrap sample)\n",
        "     - max_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9184379355819727\n",
            "Score du modèle (test) : 0.9015136316012394\n",
            "Métrique pour le modèle RandomForest+KNNImputer\n",
            "Score d'accuracy 0.9277068146860162\n",
            "Score du recall :  0.7538715410002539\n",
            "Score de la precision :  0.8199641032721248\n",
            "Score F1 :  0.7855300575358772\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     36981\n",
            "           1       0.82      0.75      0.79      7878\n",
            "\n",
            "    accuracy                           0.93     44859\n",
            "   macro avg       0.88      0.86      0.87     44859\n",
            "weighted avg       0.93      0.93      0.93     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rfkp = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(class_weight='balanced', n_estimators=170, max_depth=50, min_samples_leaf=5, max_features='sqrt'))])\n",
        "\n",
        "model_rfkp.fit(X_train, y_train)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rfkp.score(X_train, y_train)\n",
        "score_te = model_rfkp.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle RandomForest+KNNImputer\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.Iterative Imputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8981764808027145\n",
            "Score du modèle (test) : 0.8956508170043915\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.8956508170043915\n",
            "Score du recall :  0.46585427773546584\n",
            "Score de la precision :  0.8858315230509293\n",
            "Score F1 :  0.6105981199567423\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     36981\n",
            "           1       0.89      0.47      0.61      7878\n",
            "\n",
            "    accuracy                           0.90     44859\n",
            "   macro avg       0.89      0.73      0.78     44859\n",
            "weighted avg       0.89      0.90      0.88     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#on conserve les meme hyperparamètres du RandomForest précédent mais on change la méthode d'imputation avec iterative imputer\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', IterativeImputer (max_iter=20, random_state=0)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(n_estimators= 150, max_depth=45, min_samples_leaf=6, max_features='sqrt'))])\n",
        "\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = model_rf.score(X_train, y_train)\n",
        "score_te = model_rf.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "# matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le RandomForestClassifieur avec hyperparamètres:\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modélisation \n",
        "\n",
        "#### 1. Randomized search + RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'Zip', 'NewExist','CreateJob', 'RetainedJob', 'RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', ]\n",
        "num_col = ['Term', 'SBA_Appv' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'distance')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random search cv\n",
        "hyper_grid = {'classifier__max_depth':list(np.arange(60, 100, step=10)) + [30],\n",
        "              'classifier__n_estimators':[100],\n",
        "              'classifier__max_features':randint(1,7),\n",
        "              'classifier__min_samples_leaf':randint(1,4),\n",
        "              'classifier__min_samples_split':np.arange(2, 10, step=2)\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "model_rdmz_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_cv = RandomizedSearchCV(estimator= pipeline,\n",
        "                               param_distributions=hyper_grid,\n",
        "                               cv = 3,\n",
        "                               n_iter= 9,\n",
        "                               scoring = 'accuracy',\n",
        "                               n_jobs= None,\n",
        "                               return_train_score = True,\n",
        "                               random_state = 42)\n",
        "\n",
        "random_cv.fit(X_train, y_train)\n",
        "y_pred = model_rdmz_rf.predict(X_test)\n",
        "\n",
        "# Les meilleurs paramètres\n",
        "print(\"Meilleurs paramètres:\", random_cv.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = random_cv.best_estimator_.score(X_train, y_train)\n",
        "score_te = random_cv.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RandomizedSearchCV donne les résultats suivants:\n",
        "Meilleurs paramètres: {'classifier__max_depth': 70, 'classifier__max_features': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 100}\n",
        "Score du modèle (train) : 0.824524119140504\n",
        "Score du modèle (test) : 0.8231104472953844\n",
        "\n",
        "On peut restreindre la recherche d'hyperparamètres à des valeurs proches de ces résultats dans la gridsearchcv.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. GridSearch sur les hyperparamètres du RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GridSearchCv\n",
        "params = {'classifier__max_depth': [60, 70, 80],\n",
        "              'classifier__n_estimators':[90, 100, 110],\n",
        "              'classifier__max_features': [3, 4, 5],\n",
        "              'classifier__min_samples_leaf':[1,2],\n",
        "              'classifier__min_samples_split': [5,6,7]\n",
        "          }\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid = GridSearchCV(pipeline, param_grid = params, scoring = 'accuracy', cv = 4)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Meilleurs paramètres de GridSearch:\", grid.best_params_)\n",
        "\n",
        "# Performance du meilleur modèle trouvé\n",
        "score_tr = grid.best_estimator_.score(X_train, y_train)\n",
        "score_te = grid.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La gridsearch a été interrompue malheureusement car elle a nécéssité énormément de ressources informatiques pour etre calculée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "'''#separer dataset en features et target\n",
        "X = df.drop('MIS_Status', axis=1)\n",
        "y = df['MIS_Status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.05, random_state=42, stratify= y)\n",
        "\n",
        "cat_col = ['NAICS_digit', 'Zip', 'NewExist','CreateJob', 'RetainedJob', 'RevLineCr', 'LowDoc', 'FranchiseCode', 'UrbanRural', ]\n",
        "num_col = ['Term', 'SBA_Appv' ]'''\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights='distance')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.8527363347522258\n",
            "Score du modèle (test) : 0.851668561492677\n",
            "Métrique pour le modèle AdaboostClassifierr\n",
            "Score d'accuracy 0.851668561492677\n",
            "Score du recall :  0.8717948717948718\n",
            "Score de la precision :  0.5489130434782609\n",
            "Score F1 :  0.6736635605689063\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.90     36981\n",
            "           1       0.55      0.87      0.67      7878\n",
            "\n",
            "    accuracy                           0.85     44859\n",
            "   macro avg       0.76      0.86      0.79     44859\n",
            "weighted avg       0.90      0.85      0.86     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle RandomForest\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', AdaBoostClassifier())])\n",
        "\n",
        "sample_weights = compute_sample_weight(class_weight ='balanced', y= y_train)\n",
        "\n",
        "pipeline.fit(X_train, y_train, classifier__sample_weight = sample_weights)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle AdaboostClassifierr\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score du modèle (train) : 0.9032169121960606\n",
            "Score du modèle (test) : 0.8999086025100872\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.8999086025100872\n",
            "Score du recall :  0.900990099009901\n",
            "Score de la precision :  0.6567357512953368\n",
            "Score F1 :  0.7597131542331158\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94     36981\n",
            "           1       0.66      0.90      0.76      7878\n",
            "\n",
            "    accuracy                           0.90     44859\n",
            "   macro avg       0.82      0.90      0.85     44859\n",
            "weighted avg       0.92      0.90      0.91     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "weight_ratio = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy = 'median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle XGBoost\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', XGBClassifier(scale_pos_weight=weight_ratio, random_state=42))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rappel de l'encodage pour la variable MIS_Status: {'P I F': 0, 'CHGOFF': 1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.18378\n",
            "0:\tlearn: 0.5201657\ttotal: 217ms\tremaining: 3m 36s\n",
            "1:\tlearn: 0.4233822\ttotal: 334ms\tremaining: 2m 46s\n",
            "2:\tlearn: 0.3612597\ttotal: 447ms\tremaining: 2m 28s\n",
            "3:\tlearn: 0.3303949\ttotal: 577ms\tremaining: 2m 23s\n",
            "4:\tlearn: 0.3081452\ttotal: 716ms\tremaining: 2m 22s\n",
            "5:\tlearn: 0.2928329\ttotal: 835ms\tremaining: 2m 18s\n",
            "6:\tlearn: 0.2746128\ttotal: 994ms\tremaining: 2m 20s\n",
            "7:\tlearn: 0.2673302\ttotal: 1.13s\tremaining: 2m 20s\n",
            "8:\tlearn: 0.2596492\ttotal: 1.28s\tremaining: 2m 21s\n",
            "9:\tlearn: 0.2549779\ttotal: 1.45s\tremaining: 2m 23s\n",
            "10:\tlearn: 0.2513641\ttotal: 1.58s\tremaining: 2m 22s\n",
            "11:\tlearn: 0.2442544\ttotal: 1.72s\tremaining: 2m 21s\n",
            "12:\tlearn: 0.2411490\ttotal: 1.83s\tremaining: 2m 19s\n",
            "13:\tlearn: 0.2389480\ttotal: 1.94s\tremaining: 2m 16s\n",
            "14:\tlearn: 0.2364985\ttotal: 2.09s\tremaining: 2m 17s\n",
            "15:\tlearn: 0.2344247\ttotal: 2.24s\tremaining: 2m 17s\n",
            "16:\tlearn: 0.2323947\ttotal: 2.39s\tremaining: 2m 18s\n",
            "17:\tlearn: 0.2306159\ttotal: 2.53s\tremaining: 2m 17s\n",
            "18:\tlearn: 0.2287855\ttotal: 2.63s\tremaining: 2m 15s\n",
            "19:\tlearn: 0.2270692\ttotal: 2.8s\tremaining: 2m 17s\n",
            "20:\tlearn: 0.2252214\ttotal: 3.08s\tremaining: 2m 23s\n",
            "21:\tlearn: 0.2231294\ttotal: 3.28s\tremaining: 2m 25s\n",
            "22:\tlearn: 0.2218331\ttotal: 3.46s\tremaining: 2m 27s\n",
            "23:\tlearn: 0.2197608\ttotal: 3.59s\tremaining: 2m 26s\n",
            "24:\tlearn: 0.2189611\ttotal: 3.71s\tremaining: 2m 24s\n",
            "25:\tlearn: 0.2161104\ttotal: 3.84s\tremaining: 2m 23s\n",
            "26:\tlearn: 0.2147883\ttotal: 3.98s\tremaining: 2m 23s\n",
            "27:\tlearn: 0.2138112\ttotal: 4.12s\tremaining: 2m 22s\n",
            "28:\tlearn: 0.2127723\ttotal: 4.28s\tremaining: 2m 23s\n",
            "29:\tlearn: 0.2110388\ttotal: 4.42s\tremaining: 2m 22s\n",
            "30:\tlearn: 0.2102632\ttotal: 4.54s\tremaining: 2m 21s\n",
            "31:\tlearn: 0.2093473\ttotal: 4.66s\tremaining: 2m 20s\n",
            "32:\tlearn: 0.2084459\ttotal: 4.79s\tremaining: 2m 20s\n",
            "33:\tlearn: 0.2079488\ttotal: 4.89s\tremaining: 2m 18s\n",
            "34:\tlearn: 0.2069365\ttotal: 5.07s\tremaining: 2m 19s\n",
            "35:\tlearn: 0.2058255\ttotal: 5.3s\tremaining: 2m 21s\n",
            "36:\tlearn: 0.2052329\ttotal: 5.43s\tremaining: 2m 21s\n",
            "37:\tlearn: 0.2046987\ttotal: 5.57s\tremaining: 2m 21s\n",
            "38:\tlearn: 0.2039963\ttotal: 5.69s\tremaining: 2m 20s\n",
            "39:\tlearn: 0.2034961\ttotal: 5.84s\tremaining: 2m 20s\n",
            "40:\tlearn: 0.2022882\ttotal: 5.98s\tremaining: 2m 19s\n",
            "41:\tlearn: 0.2018712\ttotal: 6.17s\tremaining: 2m 20s\n",
            "42:\tlearn: 0.2013154\ttotal: 6.49s\tremaining: 2m 24s\n",
            "43:\tlearn: 0.2005824\ttotal: 6.66s\tremaining: 2m 24s\n",
            "44:\tlearn: 0.2002002\ttotal: 6.9s\tremaining: 2m 26s\n",
            "45:\tlearn: 0.1998174\ttotal: 7.08s\tremaining: 2m 26s\n",
            "46:\tlearn: 0.1992849\ttotal: 7.25s\tremaining: 2m 27s\n",
            "47:\tlearn: 0.1989531\ttotal: 7.42s\tremaining: 2m 27s\n",
            "48:\tlearn: 0.1985877\ttotal: 7.56s\tremaining: 2m 26s\n",
            "49:\tlearn: 0.1974537\ttotal: 7.68s\tremaining: 2m 25s\n",
            "50:\tlearn: 0.1970353\ttotal: 7.8s\tremaining: 2m 25s\n",
            "51:\tlearn: 0.1965795\ttotal: 7.94s\tremaining: 2m 24s\n",
            "52:\tlearn: 0.1962168\ttotal: 8.07s\tremaining: 2m 24s\n",
            "53:\tlearn: 0.1956993\ttotal: 8.21s\tremaining: 2m 23s\n",
            "54:\tlearn: 0.1954860\ttotal: 8.37s\tremaining: 2m 23s\n",
            "55:\tlearn: 0.1950803\ttotal: 8.5s\tremaining: 2m 23s\n",
            "56:\tlearn: 0.1948364\ttotal: 8.64s\tremaining: 2m 22s\n",
            "57:\tlearn: 0.1946410\ttotal: 8.8s\tremaining: 2m 22s\n",
            "58:\tlearn: 0.1942273\ttotal: 8.98s\tremaining: 2m 23s\n",
            "59:\tlearn: 0.1938280\ttotal: 9.12s\tremaining: 2m 22s\n",
            "60:\tlearn: 0.1935229\ttotal: 9.29s\tremaining: 2m 23s\n",
            "61:\tlearn: 0.1931561\ttotal: 9.6s\tremaining: 2m 25s\n",
            "62:\tlearn: 0.1929504\ttotal: 9.74s\tremaining: 2m 24s\n",
            "63:\tlearn: 0.1925746\ttotal: 9.88s\tremaining: 2m 24s\n",
            "64:\tlearn: 0.1922994\ttotal: 10s\tremaining: 2m 24s\n",
            "65:\tlearn: 0.1920736\ttotal: 10.2s\tremaining: 2m 23s\n",
            "66:\tlearn: 0.1918158\ttotal: 10.3s\tremaining: 2m 23s\n",
            "67:\tlearn: 0.1916651\ttotal: 10.4s\tremaining: 2m 22s\n",
            "68:\tlearn: 0.1913054\ttotal: 10.5s\tremaining: 2m 21s\n",
            "69:\tlearn: 0.1911694\ttotal: 10.6s\tremaining: 2m 21s\n",
            "70:\tlearn: 0.1909408\ttotal: 10.8s\tremaining: 2m 20s\n",
            "71:\tlearn: 0.1907123\ttotal: 10.9s\tremaining: 2m 19s\n",
            "72:\tlearn: 0.1904944\ttotal: 11s\tremaining: 2m 19s\n",
            "73:\tlearn: 0.1901240\ttotal: 11.1s\tremaining: 2m 18s\n",
            "74:\tlearn: 0.1899446\ttotal: 11.2s\tremaining: 2m 18s\n",
            "75:\tlearn: 0.1896867\ttotal: 11.3s\tremaining: 2m 17s\n",
            "76:\tlearn: 0.1892021\ttotal: 11.5s\tremaining: 2m 17s\n",
            "77:\tlearn: 0.1888741\ttotal: 11.7s\tremaining: 2m 18s\n",
            "78:\tlearn: 0.1887276\ttotal: 12s\tremaining: 2m 19s\n",
            "79:\tlearn: 0.1885922\ttotal: 12.1s\tremaining: 2m 19s\n",
            "80:\tlearn: 0.1884868\ttotal: 12.2s\tremaining: 2m 18s\n",
            "81:\tlearn: 0.1882851\ttotal: 12.4s\tremaining: 2m 18s\n",
            "82:\tlearn: 0.1881277\ttotal: 12.5s\tremaining: 2m 17s\n",
            "83:\tlearn: 0.1879599\ttotal: 12.6s\tremaining: 2m 17s\n",
            "84:\tlearn: 0.1877550\ttotal: 12.7s\tremaining: 2m 16s\n",
            "85:\tlearn: 0.1874677\ttotal: 12.8s\tremaining: 2m 15s\n",
            "86:\tlearn: 0.1872545\ttotal: 12.9s\tremaining: 2m 15s\n",
            "87:\tlearn: 0.1870260\ttotal: 13.1s\tremaining: 2m 15s\n",
            "88:\tlearn: 0.1868702\ttotal: 13.2s\tremaining: 2m 15s\n",
            "89:\tlearn: 0.1866482\ttotal: 13.4s\tremaining: 2m 15s\n",
            "90:\tlearn: 0.1864966\ttotal: 13.5s\tremaining: 2m 15s\n",
            "91:\tlearn: 0.1863596\ttotal: 13.6s\tremaining: 2m 14s\n",
            "92:\tlearn: 0.1862080\ttotal: 13.8s\tremaining: 2m 14s\n",
            "93:\tlearn: 0.1859670\ttotal: 14.1s\tremaining: 2m 15s\n",
            "94:\tlearn: 0.1857309\ttotal: 14.2s\tremaining: 2m 15s\n",
            "95:\tlearn: 0.1855564\ttotal: 14.3s\tremaining: 2m 15s\n",
            "96:\tlearn: 0.1854356\ttotal: 14.5s\tremaining: 2m 14s\n",
            "97:\tlearn: 0.1852565\ttotal: 14.6s\tremaining: 2m 14s\n",
            "98:\tlearn: 0.1851520\ttotal: 14.7s\tremaining: 2m 14s\n",
            "99:\tlearn: 0.1850111\ttotal: 14.9s\tremaining: 2m 13s\n",
            "100:\tlearn: 0.1848682\ttotal: 15s\tremaining: 2m 13s\n",
            "101:\tlearn: 0.1847298\ttotal: 15.1s\tremaining: 2m 13s\n",
            "102:\tlearn: 0.1845599\ttotal: 15.3s\tremaining: 2m 12s\n",
            "103:\tlearn: 0.1842836\ttotal: 15.4s\tremaining: 2m 12s\n",
            "104:\tlearn: 0.1839573\ttotal: 15.5s\tremaining: 2m 12s\n",
            "105:\tlearn: 0.1838491\ttotal: 15.8s\tremaining: 2m 12s\n",
            "106:\tlearn: 0.1835569\ttotal: 16s\tremaining: 2m 13s\n",
            "107:\tlearn: 0.1834496\ttotal: 16.2s\tremaining: 2m 13s\n",
            "108:\tlearn: 0.1833738\ttotal: 16.3s\tremaining: 2m 13s\n",
            "109:\tlearn: 0.1832808\ttotal: 16.4s\tremaining: 2m 12s\n",
            "110:\tlearn: 0.1831944\ttotal: 16.6s\tremaining: 2m 12s\n",
            "111:\tlearn: 0.1831128\ttotal: 16.7s\tremaining: 2m 12s\n",
            "112:\tlearn: 0.1829440\ttotal: 16.8s\tremaining: 2m 12s\n",
            "113:\tlearn: 0.1828208\ttotal: 17s\tremaining: 2m 12s\n",
            "114:\tlearn: 0.1826749\ttotal: 17.1s\tremaining: 2m 11s\n",
            "115:\tlearn: 0.1824506\ttotal: 17.3s\tremaining: 2m 11s\n",
            "116:\tlearn: 0.1822738\ttotal: 17.4s\tremaining: 2m 11s\n",
            "117:\tlearn: 0.1821635\ttotal: 17.6s\tremaining: 2m 11s\n",
            "118:\tlearn: 0.1820273\ttotal: 17.7s\tremaining: 2m 10s\n",
            "119:\tlearn: 0.1819371\ttotal: 17.8s\tremaining: 2m 10s\n",
            "120:\tlearn: 0.1818454\ttotal: 17.9s\tremaining: 2m 10s\n",
            "121:\tlearn: 0.1817495\ttotal: 18.1s\tremaining: 2m 10s\n",
            "122:\tlearn: 0.1815766\ttotal: 18.3s\tremaining: 2m 10s\n",
            "123:\tlearn: 0.1815008\ttotal: 18.4s\tremaining: 2m 9s\n",
            "124:\tlearn: 0.1813667\ttotal: 18.6s\tremaining: 2m 10s\n",
            "125:\tlearn: 0.1812228\ttotal: 19s\tremaining: 2m 11s\n",
            "126:\tlearn: 0.1811344\ttotal: 19.2s\tremaining: 2m 11s\n",
            "127:\tlearn: 0.1810010\ttotal: 19.4s\tremaining: 2m 11s\n",
            "128:\tlearn: 0.1808528\ttotal: 19.6s\tremaining: 2m 12s\n",
            "129:\tlearn: 0.1807373\ttotal: 19.8s\tremaining: 2m 12s\n",
            "130:\tlearn: 0.1806177\ttotal: 20s\tremaining: 2m 12s\n",
            "131:\tlearn: 0.1805593\ttotal: 20.2s\tremaining: 2m 12s\n",
            "132:\tlearn: 0.1804561\ttotal: 20.3s\tremaining: 2m 12s\n",
            "133:\tlearn: 0.1803652\ttotal: 20.4s\tremaining: 2m 12s\n",
            "134:\tlearn: 0.1802876\ttotal: 20.6s\tremaining: 2m 11s\n",
            "135:\tlearn: 0.1802323\ttotal: 20.7s\tremaining: 2m 11s\n",
            "136:\tlearn: 0.1801436\ttotal: 20.9s\tremaining: 2m 11s\n",
            "137:\tlearn: 0.1800903\ttotal: 21s\tremaining: 2m 11s\n",
            "138:\tlearn: 0.1799887\ttotal: 21.2s\tremaining: 2m 11s\n",
            "139:\tlearn: 0.1798816\ttotal: 21.3s\tremaining: 2m 10s\n",
            "140:\tlearn: 0.1797736\ttotal: 21.7s\tremaining: 2m 12s\n",
            "141:\tlearn: 0.1797176\ttotal: 21.9s\tremaining: 2m 12s\n",
            "142:\tlearn: 0.1796492\ttotal: 22.1s\tremaining: 2m 12s\n",
            "143:\tlearn: 0.1795658\ttotal: 22.2s\tremaining: 2m 11s\n",
            "144:\tlearn: 0.1794190\ttotal: 22.3s\tremaining: 2m 11s\n",
            "145:\tlearn: 0.1793267\ttotal: 22.4s\tremaining: 2m 11s\n",
            "146:\tlearn: 0.1792765\ttotal: 22.6s\tremaining: 2m 10s\n",
            "147:\tlearn: 0.1792094\ttotal: 22.7s\tremaining: 2m 10s\n",
            "148:\tlearn: 0.1791203\ttotal: 22.8s\tremaining: 2m 10s\n",
            "149:\tlearn: 0.1790368\ttotal: 22.9s\tremaining: 2m 9s\n",
            "150:\tlearn: 0.1789843\ttotal: 23s\tremaining: 2m 9s\n",
            "151:\tlearn: 0.1789392\ttotal: 23.1s\tremaining: 2m 9s\n",
            "152:\tlearn: 0.1788788\ttotal: 23.2s\tremaining: 2m 8s\n",
            "153:\tlearn: 0.1787707\ttotal: 23.4s\tremaining: 2m 8s\n",
            "154:\tlearn: 0.1787240\ttotal: 23.5s\tremaining: 2m 8s\n",
            "155:\tlearn: 0.1786779\ttotal: 23.6s\tremaining: 2m 7s\n",
            "156:\tlearn: 0.1786140\ttotal: 23.7s\tremaining: 2m 7s\n",
            "157:\tlearn: 0.1784374\ttotal: 23.9s\tremaining: 2m 7s\n",
            "158:\tlearn: 0.1783374\ttotal: 24.3s\tremaining: 2m 8s\n",
            "159:\tlearn: 0.1782435\ttotal: 24.4s\tremaining: 2m 8s\n",
            "160:\tlearn: 0.1780615\ttotal: 24.7s\tremaining: 2m 8s\n",
            "161:\tlearn: 0.1779989\ttotal: 24.8s\tremaining: 2m 8s\n",
            "162:\tlearn: 0.1779296\ttotal: 24.9s\tremaining: 2m 8s\n",
            "163:\tlearn: 0.1778553\ttotal: 25.1s\tremaining: 2m 7s\n",
            "164:\tlearn: 0.1777927\ttotal: 25.2s\tremaining: 2m 7s\n",
            "165:\tlearn: 0.1777483\ttotal: 25.3s\tremaining: 2m 7s\n",
            "166:\tlearn: 0.1776750\ttotal: 25.4s\tremaining: 2m 6s\n",
            "167:\tlearn: 0.1775269\ttotal: 25.6s\tremaining: 2m 6s\n",
            "168:\tlearn: 0.1774523\ttotal: 25.7s\tremaining: 2m 6s\n",
            "169:\tlearn: 0.1773915\ttotal: 25.8s\tremaining: 2m 6s\n",
            "170:\tlearn: 0.1773219\ttotal: 25.9s\tremaining: 2m 5s\n",
            "171:\tlearn: 0.1772855\ttotal: 26s\tremaining: 2m 5s\n",
            "172:\tlearn: 0.1772555\ttotal: 26.1s\tremaining: 2m 4s\n",
            "173:\tlearn: 0.1772173\ttotal: 26.2s\tremaining: 2m 4s\n",
            "174:\tlearn: 0.1771613\ttotal: 26.5s\tremaining: 2m 4s\n",
            "175:\tlearn: 0.1770583\ttotal: 26.7s\tremaining: 2m 5s\n",
            "176:\tlearn: 0.1769831\ttotal: 26.9s\tremaining: 2m 5s\n",
            "177:\tlearn: 0.1769464\ttotal: 27s\tremaining: 2m 4s\n",
            "178:\tlearn: 0.1768779\ttotal: 27.1s\tremaining: 2m 4s\n",
            "179:\tlearn: 0.1768443\ttotal: 27.3s\tremaining: 2m 4s\n",
            "180:\tlearn: 0.1767735\ttotal: 27.4s\tremaining: 2m 3s\n",
            "181:\tlearn: 0.1766827\ttotal: 27.5s\tremaining: 2m 3s\n",
            "182:\tlearn: 0.1766175\ttotal: 27.6s\tremaining: 2m 3s\n",
            "183:\tlearn: 0.1765267\ttotal: 27.7s\tremaining: 2m 3s\n",
            "184:\tlearn: 0.1764687\ttotal: 27.9s\tremaining: 2m 2s\n",
            "185:\tlearn: 0.1763901\ttotal: 28s\tremaining: 2m 2s\n",
            "186:\tlearn: 0.1763383\ttotal: 28.1s\tremaining: 2m 2s\n",
            "187:\tlearn: 0.1763081\ttotal: 28.5s\tremaining: 2m 3s\n",
            "188:\tlearn: 0.1762452\ttotal: 28.7s\tremaining: 2m 3s\n",
            "189:\tlearn: 0.1761694\ttotal: 28.9s\tremaining: 2m 3s\n",
            "190:\tlearn: 0.1761030\ttotal: 29s\tremaining: 2m 2s\n",
            "191:\tlearn: 0.1760305\ttotal: 29.1s\tremaining: 2m 2s\n",
            "192:\tlearn: 0.1759804\ttotal: 29.3s\tremaining: 2m 2s\n",
            "193:\tlearn: 0.1759286\ttotal: 29.4s\tremaining: 2m 2s\n",
            "194:\tlearn: 0.1758808\ttotal: 29.5s\tremaining: 2m 1s\n",
            "195:\tlearn: 0.1757450\ttotal: 29.6s\tremaining: 2m 1s\n",
            "196:\tlearn: 0.1756311\ttotal: 29.7s\tremaining: 2m 1s\n",
            "197:\tlearn: 0.1755192\ttotal: 29.8s\tremaining: 2m\n",
            "198:\tlearn: 0.1754632\ttotal: 29.9s\tremaining: 2m\n",
            "199:\tlearn: 0.1754110\ttotal: 30.2s\tremaining: 2m\n",
            "200:\tlearn: 0.1753765\ttotal: 30.4s\tremaining: 2m\n",
            "201:\tlearn: 0.1753364\ttotal: 30.5s\tremaining: 2m\n",
            "202:\tlearn: 0.1752967\ttotal: 30.6s\tremaining: 2m\n",
            "203:\tlearn: 0.1752691\ttotal: 30.7s\tremaining: 1m 59s\n",
            "204:\tlearn: 0.1752310\ttotal: 30.9s\tremaining: 1m 59s\n",
            "205:\tlearn: 0.1751720\ttotal: 31s\tremaining: 1m 59s\n",
            "206:\tlearn: 0.1751309\ttotal: 31.1s\tremaining: 1m 59s\n",
            "207:\tlearn: 0.1750788\ttotal: 31.2s\tremaining: 1m 58s\n",
            "208:\tlearn: 0.1750424\ttotal: 31.4s\tremaining: 1m 58s\n",
            "209:\tlearn: 0.1749560\ttotal: 31.6s\tremaining: 1m 58s\n",
            "210:\tlearn: 0.1748979\ttotal: 31.8s\tremaining: 1m 58s\n",
            "211:\tlearn: 0.1748778\ttotal: 31.9s\tremaining: 1m 58s\n",
            "212:\tlearn: 0.1748281\ttotal: 32.1s\tremaining: 1m 58s\n",
            "213:\tlearn: 0.1747847\ttotal: 32.3s\tremaining: 1m 58s\n",
            "214:\tlearn: 0.1747468\ttotal: 32.5s\tremaining: 1m 58s\n",
            "215:\tlearn: 0.1747184\ttotal: 32.6s\tremaining: 1m 58s\n",
            "216:\tlearn: 0.1746943\ttotal: 32.9s\tremaining: 1m 58s\n",
            "217:\tlearn: 0.1746548\ttotal: 33.2s\tremaining: 1m 58s\n",
            "218:\tlearn: 0.1746214\ttotal: 33.3s\tremaining: 1m 58s\n",
            "219:\tlearn: 0.1745942\ttotal: 33.4s\tremaining: 1m 58s\n",
            "220:\tlearn: 0.1745491\ttotal: 33.6s\tremaining: 1m 58s\n",
            "221:\tlearn: 0.1745217\ttotal: 33.8s\tremaining: 1m 58s\n",
            "222:\tlearn: 0.1744665\ttotal: 34s\tremaining: 1m 58s\n",
            "223:\tlearn: 0.1744207\ttotal: 34.1s\tremaining: 1m 58s\n",
            "224:\tlearn: 0.1743683\ttotal: 34.2s\tremaining: 1m 57s\n",
            "225:\tlearn: 0.1743425\ttotal: 34.3s\tremaining: 1m 57s\n",
            "226:\tlearn: 0.1743088\ttotal: 34.4s\tremaining: 1m 57s\n",
            "227:\tlearn: 0.1742502\ttotal: 34.5s\tremaining: 1m 56s\n",
            "228:\tlearn: 0.1741941\ttotal: 34.6s\tremaining: 1m 56s\n",
            "229:\tlearn: 0.1741483\ttotal: 34.8s\tremaining: 1m 56s\n",
            "230:\tlearn: 0.1740982\ttotal: 34.9s\tremaining: 1m 56s\n",
            "231:\tlearn: 0.1740187\ttotal: 35s\tremaining: 1m 55s\n",
            "232:\tlearn: 0.1739924\ttotal: 35.2s\tremaining: 1m 55s\n",
            "233:\tlearn: 0.1739595\ttotal: 35.3s\tremaining: 1m 55s\n",
            "234:\tlearn: 0.1739278\ttotal: 35.6s\tremaining: 1m 55s\n",
            "235:\tlearn: 0.1738931\ttotal: 35.7s\tremaining: 1m 55s\n",
            "236:\tlearn: 0.1738119\ttotal: 35.8s\tremaining: 1m 55s\n",
            "237:\tlearn: 0.1737868\ttotal: 35.9s\tremaining: 1m 55s\n",
            "238:\tlearn: 0.1737639\ttotal: 36.1s\tremaining: 1m 54s\n",
            "239:\tlearn: 0.1737069\ttotal: 36.2s\tremaining: 1m 54s\n",
            "240:\tlearn: 0.1736764\ttotal: 36.3s\tremaining: 1m 54s\n",
            "241:\tlearn: 0.1736005\ttotal: 36.4s\tremaining: 1m 54s\n",
            "242:\tlearn: 0.1735042\ttotal: 36.6s\tremaining: 1m 53s\n",
            "243:\tlearn: 0.1734622\ttotal: 36.7s\tremaining: 1m 53s\n",
            "244:\tlearn: 0.1734315\ttotal: 36.8s\tremaining: 1m 53s\n",
            "245:\tlearn: 0.1733890\ttotal: 36.9s\tremaining: 1m 53s\n",
            "246:\tlearn: 0.1733498\ttotal: 37s\tremaining: 1m 52s\n",
            "247:\tlearn: 0.1733080\ttotal: 37.1s\tremaining: 1m 52s\n",
            "248:\tlearn: 0.1732739\ttotal: 37.2s\tremaining: 1m 52s\n",
            "249:\tlearn: 0.1732386\ttotal: 37.4s\tremaining: 1m 52s\n",
            "250:\tlearn: 0.1732190\ttotal: 37.5s\tremaining: 1m 51s\n",
            "251:\tlearn: 0.1731807\ttotal: 37.6s\tremaining: 1m 51s\n",
            "252:\tlearn: 0.1731527\ttotal: 37.7s\tremaining: 1m 51s\n",
            "253:\tlearn: 0.1731097\ttotal: 37.9s\tremaining: 1m 51s\n",
            "254:\tlearn: 0.1730872\ttotal: 38s\tremaining: 1m 51s\n",
            "255:\tlearn: 0.1730727\ttotal: 38.2s\tremaining: 1m 50s\n",
            "256:\tlearn: 0.1730417\ttotal: 38.3s\tremaining: 1m 50s\n",
            "257:\tlearn: 0.1730149\ttotal: 38.5s\tremaining: 1m 50s\n",
            "258:\tlearn: 0.1729875\ttotal: 38.8s\tremaining: 1m 50s\n",
            "259:\tlearn: 0.1729666\ttotal: 38.9s\tremaining: 1m 50s\n",
            "260:\tlearn: 0.1729430\ttotal: 39.1s\tremaining: 1m 50s\n",
            "261:\tlearn: 0.1729135\ttotal: 39.3s\tremaining: 1m 50s\n",
            "262:\tlearn: 0.1728828\ttotal: 39.4s\tremaining: 1m 50s\n",
            "263:\tlearn: 0.1728598\ttotal: 39.5s\tremaining: 1m 50s\n",
            "264:\tlearn: 0.1728136\ttotal: 39.7s\tremaining: 1m 50s\n",
            "265:\tlearn: 0.1727793\ttotal: 39.8s\tremaining: 1m 49s\n",
            "266:\tlearn: 0.1727275\ttotal: 39.9s\tremaining: 1m 49s\n",
            "267:\tlearn: 0.1726882\ttotal: 40s\tremaining: 1m 49s\n",
            "268:\tlearn: 0.1726567\ttotal: 40.1s\tremaining: 1m 49s\n",
            "269:\tlearn: 0.1725999\ttotal: 40.3s\tremaining: 1m 48s\n",
            "270:\tlearn: 0.1725801\ttotal: 40.4s\tremaining: 1m 48s\n",
            "271:\tlearn: 0.1724780\ttotal: 40.5s\tremaining: 1m 48s\n",
            "272:\tlearn: 0.1724462\ttotal: 40.6s\tremaining: 1m 48s\n",
            "273:\tlearn: 0.1724166\ttotal: 40.7s\tremaining: 1m 47s\n",
            "274:\tlearn: 0.1723876\ttotal: 40.9s\tremaining: 1m 47s\n",
            "275:\tlearn: 0.1723638\ttotal: 41s\tremaining: 1m 47s\n",
            "276:\tlearn: 0.1723378\ttotal: 41.3s\tremaining: 1m 47s\n",
            "277:\tlearn: 0.1723004\ttotal: 41.6s\tremaining: 1m 47s\n",
            "278:\tlearn: 0.1722584\ttotal: 41.8s\tremaining: 1m 47s\n",
            "279:\tlearn: 0.1722308\ttotal: 41.9s\tremaining: 1m 47s\n",
            "280:\tlearn: 0.1721964\ttotal: 42s\tremaining: 1m 47s\n",
            "281:\tlearn: 0.1721816\ttotal: 42.2s\tremaining: 1m 47s\n",
            "282:\tlearn: 0.1721556\ttotal: 42.3s\tremaining: 1m 47s\n",
            "283:\tlearn: 0.1721371\ttotal: 42.4s\tremaining: 1m 46s\n",
            "284:\tlearn: 0.1721198\ttotal: 42.5s\tremaining: 1m 46s\n",
            "285:\tlearn: 0.1720950\ttotal: 42.7s\tremaining: 1m 46s\n",
            "286:\tlearn: 0.1720710\ttotal: 42.8s\tremaining: 1m 46s\n",
            "287:\tlearn: 0.1720506\ttotal: 42.9s\tremaining: 1m 46s\n",
            "288:\tlearn: 0.1720318\ttotal: 43s\tremaining: 1m 45s\n",
            "289:\tlearn: 0.1719613\ttotal: 43.2s\tremaining: 1m 45s\n",
            "290:\tlearn: 0.1719446\ttotal: 43.3s\tremaining: 1m 45s\n",
            "291:\tlearn: 0.1719302\ttotal: 43.4s\tremaining: 1m 45s\n",
            "292:\tlearn: 0.1719025\ttotal: 43.5s\tremaining: 1m 45s\n",
            "293:\tlearn: 0.1718508\ttotal: 43.6s\tremaining: 1m 44s\n",
            "294:\tlearn: 0.1718228\ttotal: 43.8s\tremaining: 1m 44s\n",
            "295:\tlearn: 0.1718089\ttotal: 43.9s\tremaining: 1m 44s\n",
            "296:\tlearn: 0.1717841\ttotal: 44.2s\tremaining: 1m 44s\n",
            "297:\tlearn: 0.1717672\ttotal: 44.4s\tremaining: 1m 44s\n",
            "298:\tlearn: 0.1716567\ttotal: 44.6s\tremaining: 1m 44s\n",
            "299:\tlearn: 0.1716268\ttotal: 44.8s\tremaining: 1m 44s\n",
            "300:\tlearn: 0.1715837\ttotal: 45s\tremaining: 1m 44s\n",
            "301:\tlearn: 0.1715625\ttotal: 45.1s\tremaining: 1m 44s\n",
            "302:\tlearn: 0.1715011\ttotal: 45.3s\tremaining: 1m 44s\n",
            "303:\tlearn: 0.1714665\ttotal: 45.4s\tremaining: 1m 44s\n",
            "304:\tlearn: 0.1713989\ttotal: 45.6s\tremaining: 1m 43s\n",
            "305:\tlearn: 0.1713695\ttotal: 45.7s\tremaining: 1m 43s\n",
            "306:\tlearn: 0.1713520\ttotal: 45.8s\tremaining: 1m 43s\n",
            "307:\tlearn: 0.1713371\ttotal: 45.9s\tremaining: 1m 43s\n",
            "308:\tlearn: 0.1712890\ttotal: 46.1s\tremaining: 1m 43s\n",
            "309:\tlearn: 0.1712637\ttotal: 46.2s\tremaining: 1m 42s\n",
            "310:\tlearn: 0.1712157\ttotal: 46.3s\tremaining: 1m 42s\n",
            "311:\tlearn: 0.1711989\ttotal: 46.4s\tremaining: 1m 42s\n",
            "312:\tlearn: 0.1711837\ttotal: 46.5s\tremaining: 1m 42s\n",
            "313:\tlearn: 0.1711568\ttotal: 46.7s\tremaining: 1m 42s\n",
            "314:\tlearn: 0.1711376\ttotal: 46.8s\tremaining: 1m 41s\n",
            "315:\tlearn: 0.1711224\ttotal: 46.9s\tremaining: 1m 41s\n",
            "316:\tlearn: 0.1711073\ttotal: 47.1s\tremaining: 1m 41s\n",
            "317:\tlearn: 0.1710931\ttotal: 47.3s\tremaining: 1m 41s\n",
            "318:\tlearn: 0.1710604\ttotal: 47.8s\tremaining: 1m 41s\n",
            "319:\tlearn: 0.1710371\ttotal: 48s\tremaining: 1m 42s\n",
            "320:\tlearn: 0.1710083\ttotal: 48.2s\tremaining: 1m 41s\n",
            "321:\tlearn: 0.1709816\ttotal: 48.5s\tremaining: 1m 42s\n",
            "322:\tlearn: 0.1709652\ttotal: 48.6s\tremaining: 1m 41s\n",
            "323:\tlearn: 0.1709446\ttotal: 48.8s\tremaining: 1m 41s\n",
            "324:\tlearn: 0.1709341\ttotal: 48.9s\tremaining: 1m 41s\n",
            "325:\tlearn: 0.1709192\ttotal: 49.1s\tremaining: 1m 41s\n",
            "326:\tlearn: 0.1708907\ttotal: 49.2s\tremaining: 1m 41s\n",
            "327:\tlearn: 0.1708722\ttotal: 49.3s\tremaining: 1m 40s\n",
            "328:\tlearn: 0.1708609\ttotal: 49.4s\tremaining: 1m 40s\n",
            "329:\tlearn: 0.1708400\ttotal: 49.5s\tremaining: 1m 40s\n",
            "330:\tlearn: 0.1708021\ttotal: 49.6s\tremaining: 1m 40s\n",
            "331:\tlearn: 0.1707929\ttotal: 49.8s\tremaining: 1m 40s\n",
            "332:\tlearn: 0.1707625\ttotal: 49.9s\tremaining: 1m 39s\n",
            "333:\tlearn: 0.1707313\ttotal: 50s\tremaining: 1m 39s\n",
            "334:\tlearn: 0.1707084\ttotal: 50.2s\tremaining: 1m 39s\n",
            "335:\tlearn: 0.1706933\ttotal: 50.5s\tremaining: 1m 39s\n",
            "336:\tlearn: 0.1706708\ttotal: 50.8s\tremaining: 1m 39s\n",
            "337:\tlearn: 0.1706422\ttotal: 50.9s\tremaining: 1m 39s\n",
            "338:\tlearn: 0.1706156\ttotal: 51.1s\tremaining: 1m 39s\n",
            "339:\tlearn: 0.1706003\ttotal: 51.3s\tremaining: 1m 39s\n",
            "340:\tlearn: 0.1705801\ttotal: 51.4s\tremaining: 1m 39s\n",
            "341:\tlearn: 0.1705694\ttotal: 51.6s\tremaining: 1m 39s\n",
            "342:\tlearn: 0.1705501\ttotal: 51.8s\tremaining: 1m 39s\n",
            "343:\tlearn: 0.1705018\ttotal: 51.9s\tremaining: 1m 38s\n",
            "344:\tlearn: 0.1704806\ttotal: 52s\tremaining: 1m 38s\n",
            "345:\tlearn: 0.1704658\ttotal: 52.1s\tremaining: 1m 38s\n",
            "346:\tlearn: 0.1704316\ttotal: 52.2s\tremaining: 1m 38s\n",
            "347:\tlearn: 0.1703941\ttotal: 52.4s\tremaining: 1m 38s\n",
            "348:\tlearn: 0.1703529\ttotal: 52.6s\tremaining: 1m 38s\n",
            "349:\tlearn: 0.1703346\ttotal: 53.1s\tremaining: 1m 38s\n",
            "350:\tlearn: 0.1703218\ttotal: 53.4s\tremaining: 1m 38s\n",
            "351:\tlearn: 0.1703019\ttotal: 53.6s\tremaining: 1m 38s\n",
            "352:\tlearn: 0.1702589\ttotal: 53.8s\tremaining: 1m 38s\n",
            "353:\tlearn: 0.1702346\ttotal: 54s\tremaining: 1m 38s\n",
            "354:\tlearn: 0.1702033\ttotal: 54.1s\tremaining: 1m 38s\n",
            "355:\tlearn: 0.1701912\ttotal: 54.2s\tremaining: 1m 38s\n",
            "356:\tlearn: 0.1701473\ttotal: 54.3s\tremaining: 1m 37s\n",
            "357:\tlearn: 0.1701182\ttotal: 54.4s\tremaining: 1m 37s\n",
            "358:\tlearn: 0.1701015\ttotal: 54.6s\tremaining: 1m 37s\n",
            "359:\tlearn: 0.1700648\ttotal: 54.7s\tremaining: 1m 37s\n",
            "360:\tlearn: 0.1700427\ttotal: 54.8s\tremaining: 1m 37s\n",
            "361:\tlearn: 0.1700222\ttotal: 55s\tremaining: 1m 36s\n",
            "362:\tlearn: 0.1700084\ttotal: 55.1s\tremaining: 1m 36s\n",
            "363:\tlearn: 0.1699948\ttotal: 55.3s\tremaining: 1m 36s\n",
            "364:\tlearn: 0.1699684\ttotal: 55.6s\tremaining: 1m 36s\n",
            "365:\tlearn: 0.1699547\ttotal: 55.9s\tremaining: 1m 36s\n",
            "366:\tlearn: 0.1699365\ttotal: 56s\tremaining: 1m 36s\n",
            "367:\tlearn: 0.1699175\ttotal: 56.1s\tremaining: 1m 36s\n",
            "368:\tlearn: 0.1699040\ttotal: 56.3s\tremaining: 1m 36s\n",
            "369:\tlearn: 0.1698843\ttotal: 56.4s\tremaining: 1m 36s\n",
            "370:\tlearn: 0.1697933\ttotal: 56.6s\tremaining: 1m 35s\n",
            "371:\tlearn: 0.1697684\ttotal: 56.7s\tremaining: 1m 35s\n",
            "372:\tlearn: 0.1697451\ttotal: 56.8s\tremaining: 1m 35s\n",
            "373:\tlearn: 0.1697278\ttotal: 57s\tremaining: 1m 35s\n",
            "374:\tlearn: 0.1697178\ttotal: 57.1s\tremaining: 1m 35s\n",
            "375:\tlearn: 0.1697000\ttotal: 57.2s\tremaining: 1m 34s\n",
            "376:\tlearn: 0.1696836\ttotal: 57.4s\tremaining: 1m 34s\n",
            "377:\tlearn: 0.1696704\ttotal: 57.5s\tremaining: 1m 34s\n",
            "378:\tlearn: 0.1696400\ttotal: 57.6s\tremaining: 1m 34s\n",
            "379:\tlearn: 0.1696233\ttotal: 57.7s\tremaining: 1m 34s\n",
            "380:\tlearn: 0.1696009\ttotal: 57.9s\tremaining: 1m 34s\n",
            "381:\tlearn: 0.1695913\ttotal: 58.1s\tremaining: 1m 33s\n",
            "382:\tlearn: 0.1695706\ttotal: 58.3s\tremaining: 1m 33s\n",
            "383:\tlearn: 0.1695557\ttotal: 58.4s\tremaining: 1m 33s\n",
            "384:\tlearn: 0.1695336\ttotal: 58.9s\tremaining: 1m 34s\n",
            "385:\tlearn: 0.1695128\ttotal: 59.1s\tremaining: 1m 34s\n",
            "386:\tlearn: 0.1694829\ttotal: 59.4s\tremaining: 1m 34s\n",
            "387:\tlearn: 0.1694661\ttotal: 59.6s\tremaining: 1m 34s\n",
            "388:\tlearn: 0.1694391\ttotal: 59.8s\tremaining: 1m 33s\n",
            "389:\tlearn: 0.1694298\ttotal: 59.9s\tremaining: 1m 33s\n",
            "390:\tlearn: 0.1694164\ttotal: 1m\tremaining: 1m 33s\n",
            "391:\tlearn: 0.1694003\ttotal: 1m\tremaining: 1m 33s\n",
            "392:\tlearn: 0.1693892\ttotal: 1m\tremaining: 1m 33s\n",
            "393:\tlearn: 0.1693542\ttotal: 1m\tremaining: 1m 33s\n",
            "394:\tlearn: 0.1693462\ttotal: 1m\tremaining: 1m 32s\n",
            "395:\tlearn: 0.1693251\ttotal: 1m\tremaining: 1m 32s\n",
            "396:\tlearn: 0.1693144\ttotal: 1m\tremaining: 1m 32s\n",
            "397:\tlearn: 0.1693010\ttotal: 1m 1s\tremaining: 1m 32s\n",
            "398:\tlearn: 0.1692906\ttotal: 1m 1s\tremaining: 1m 32s\n",
            "399:\tlearn: 0.1692718\ttotal: 1m 1s\tremaining: 1m 32s\n",
            "400:\tlearn: 0.1692356\ttotal: 1m 1s\tremaining: 1m 31s\n",
            "401:\tlearn: 0.1692163\ttotal: 1m 1s\tremaining: 1m 31s\n",
            "402:\tlearn: 0.1691949\ttotal: 1m 1s\tremaining: 1m 31s\n",
            "403:\tlearn: 0.1691824\ttotal: 1m 1s\tremaining: 1m 31s\n",
            "404:\tlearn: 0.1691583\ttotal: 1m 2s\tremaining: 1m 31s\n",
            "405:\tlearn: 0.1691327\ttotal: 1m 2s\tremaining: 1m 31s\n",
            "406:\tlearn: 0.1691146\ttotal: 1m 2s\tremaining: 1m 31s\n",
            "407:\tlearn: 0.1691009\ttotal: 1m 2s\tremaining: 1m 31s\n",
            "408:\tlearn: 0.1690874\ttotal: 1m 2s\tremaining: 1m 30s\n",
            "409:\tlearn: 0.1690758\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "410:\tlearn: 0.1690630\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "411:\tlearn: 0.1690553\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "412:\tlearn: 0.1690404\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "413:\tlearn: 0.1690098\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "414:\tlearn: 0.1689980\ttotal: 1m 3s\tremaining: 1m 29s\n",
            "415:\tlearn: 0.1689769\ttotal: 1m 3s\tremaining: 1m 29s\n",
            "416:\tlearn: 0.1689654\ttotal: 1m 4s\tremaining: 1m 29s\n",
            "417:\tlearn: 0.1689460\ttotal: 1m 4s\tremaining: 1m 29s\n",
            "418:\tlearn: 0.1689365\ttotal: 1m 4s\tremaining: 1m 29s\n",
            "419:\tlearn: 0.1689211\ttotal: 1m 4s\tremaining: 1m 28s\n",
            "420:\tlearn: 0.1689093\ttotal: 1m 4s\tremaining: 1m 28s\n",
            "421:\tlearn: 0.1688562\ttotal: 1m 4s\tremaining: 1m 28s\n",
            "422:\tlearn: 0.1688423\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "423:\tlearn: 0.1688271\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "424:\tlearn: 0.1688110\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "425:\tlearn: 0.1687937\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "426:\tlearn: 0.1687864\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "427:\tlearn: 0.1687677\ttotal: 1m 5s\tremaining: 1m 27s\n",
            "428:\tlearn: 0.1687541\ttotal: 1m 5s\tremaining: 1m 27s\n",
            "429:\tlearn: 0.1687270\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "430:\tlearn: 0.1686988\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "431:\tlearn: 0.1686866\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "432:\tlearn: 0.1686676\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "433:\tlearn: 0.1686547\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "434:\tlearn: 0.1686401\ttotal: 1m 6s\tremaining: 1m 26s\n",
            "435:\tlearn: 0.1686279\ttotal: 1m 7s\tremaining: 1m 26s\n",
            "436:\tlearn: 0.1686105\ttotal: 1m 7s\tremaining: 1m 26s\n",
            "437:\tlearn: 0.1685985\ttotal: 1m 7s\tremaining: 1m 26s\n",
            "438:\tlearn: 0.1685914\ttotal: 1m 7s\tremaining: 1m 26s\n",
            "439:\tlearn: 0.1685763\ttotal: 1m 7s\tremaining: 1m 25s\n",
            "440:\tlearn: 0.1685598\ttotal: 1m 7s\tremaining: 1m 25s\n",
            "441:\tlearn: 0.1685491\ttotal: 1m 7s\tremaining: 1m 25s\n",
            "442:\tlearn: 0.1685284\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "443:\tlearn: 0.1685057\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "444:\tlearn: 0.1684792\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "445:\tlearn: 0.1684599\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "446:\tlearn: 0.1684390\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "447:\tlearn: 0.1684228\ttotal: 1m 9s\tremaining: 1m 25s\n",
            "448:\tlearn: 0.1684035\ttotal: 1m 9s\tremaining: 1m 25s\n",
            "449:\tlearn: 0.1683811\ttotal: 1m 9s\tremaining: 1m 24s\n",
            "450:\tlearn: 0.1683631\ttotal: 1m 9s\tremaining: 1m 24s\n",
            "451:\tlearn: 0.1683440\ttotal: 1m 9s\tremaining: 1m 24s\n",
            "452:\tlearn: 0.1683326\ttotal: 1m 9s\tremaining: 1m 24s\n",
            "453:\tlearn: 0.1683133\ttotal: 1m 10s\tremaining: 1m 24s\n",
            "454:\tlearn: 0.1682955\ttotal: 1m 10s\tremaining: 1m 24s\n",
            "455:\tlearn: 0.1682834\ttotal: 1m 10s\tremaining: 1m 24s\n",
            "456:\tlearn: 0.1682733\ttotal: 1m 10s\tremaining: 1m 24s\n",
            "457:\tlearn: 0.1682488\ttotal: 1m 10s\tremaining: 1m 24s\n",
            "458:\tlearn: 0.1682279\ttotal: 1m 11s\tremaining: 1m 23s\n",
            "459:\tlearn: 0.1682097\ttotal: 1m 11s\tremaining: 1m 23s\n",
            "460:\tlearn: 0.1681887\ttotal: 1m 11s\tremaining: 1m 23s\n",
            "461:\tlearn: 0.1681730\ttotal: 1m 11s\tremaining: 1m 23s\n",
            "462:\tlearn: 0.1681533\ttotal: 1m 11s\tremaining: 1m 23s\n",
            "463:\tlearn: 0.1681316\ttotal: 1m 11s\tremaining: 1m 22s\n",
            "464:\tlearn: 0.1681166\ttotal: 1m 11s\tremaining: 1m 22s\n",
            "465:\tlearn: 0.1680993\ttotal: 1m 12s\tremaining: 1m 22s\n",
            "466:\tlearn: 0.1680862\ttotal: 1m 12s\tremaining: 1m 22s\n",
            "467:\tlearn: 0.1680736\ttotal: 1m 12s\tremaining: 1m 22s\n",
            "468:\tlearn: 0.1680589\ttotal: 1m 12s\tremaining: 1m 22s\n",
            "469:\tlearn: 0.1680429\ttotal: 1m 12s\tremaining: 1m 21s\n",
            "470:\tlearn: 0.1680306\ttotal: 1m 12s\tremaining: 1m 21s\n",
            "471:\tlearn: 0.1680144\ttotal: 1m 12s\tremaining: 1m 21s\n",
            "472:\tlearn: 0.1680003\ttotal: 1m 13s\tremaining: 1m 21s\n",
            "473:\tlearn: 0.1679851\ttotal: 1m 13s\tremaining: 1m 21s\n",
            "474:\tlearn: 0.1679738\ttotal: 1m 13s\tremaining: 1m 20s\n",
            "475:\tlearn: 0.1679624\ttotal: 1m 13s\tremaining: 1m 20s\n",
            "476:\tlearn: 0.1679541\ttotal: 1m 13s\tremaining: 1m 20s\n",
            "477:\tlearn: 0.1679367\ttotal: 1m 13s\tremaining: 1m 20s\n",
            "478:\tlearn: 0.1679206\ttotal: 1m 14s\tremaining: 1m 20s\n",
            "479:\tlearn: 0.1679099\ttotal: 1m 14s\tremaining: 1m 20s\n",
            "480:\tlearn: 0.1678999\ttotal: 1m 14s\tremaining: 1m 20s\n",
            "481:\tlearn: 0.1678887\ttotal: 1m 14s\tremaining: 1m 20s\n",
            "482:\tlearn: 0.1678796\ttotal: 1m 14s\tremaining: 1m 19s\n",
            "483:\tlearn: 0.1678655\ttotal: 1m 14s\tremaining: 1m 19s\n",
            "484:\tlearn: 0.1678585\ttotal: 1m 14s\tremaining: 1m 19s\n",
            "485:\tlearn: 0.1678486\ttotal: 1m 15s\tremaining: 1m 19s\n",
            "486:\tlearn: 0.1678397\ttotal: 1m 15s\tremaining: 1m 19s\n",
            "487:\tlearn: 0.1678248\ttotal: 1m 15s\tremaining: 1m 19s\n",
            "488:\tlearn: 0.1678045\ttotal: 1m 15s\tremaining: 1m 18s\n",
            "489:\tlearn: 0.1677936\ttotal: 1m 15s\tremaining: 1m 18s\n",
            "490:\tlearn: 0.1677769\ttotal: 1m 15s\tremaining: 1m 18s\n",
            "491:\tlearn: 0.1677667\ttotal: 1m 15s\tremaining: 1m 18s\n",
            "492:\tlearn: 0.1677563\ttotal: 1m 16s\tremaining: 1m 18s\n",
            "493:\tlearn: 0.1677418\ttotal: 1m 16s\tremaining: 1m 18s\n",
            "494:\tlearn: 0.1677252\ttotal: 1m 16s\tremaining: 1m 18s\n",
            "495:\tlearn: 0.1677144\ttotal: 1m 16s\tremaining: 1m 17s\n",
            "496:\tlearn: 0.1677006\ttotal: 1m 16s\tremaining: 1m 17s\n",
            "497:\tlearn: 0.1676888\ttotal: 1m 16s\tremaining: 1m 17s\n",
            "498:\tlearn: 0.1676797\ttotal: 1m 17s\tremaining: 1m 17s\n",
            "499:\tlearn: 0.1676725\ttotal: 1m 17s\tremaining: 1m 17s\n",
            "500:\tlearn: 0.1676614\ttotal: 1m 17s\tremaining: 1m 17s\n",
            "501:\tlearn: 0.1676495\ttotal: 1m 17s\tremaining: 1m 17s\n",
            "502:\tlearn: 0.1676321\ttotal: 1m 17s\tremaining: 1m 17s\n",
            "503:\tlearn: 0.1676088\ttotal: 1m 18s\tremaining: 1m 16s\n",
            "504:\tlearn: 0.1675932\ttotal: 1m 18s\tremaining: 1m 16s\n",
            "505:\tlearn: 0.1675617\ttotal: 1m 18s\tremaining: 1m 16s\n",
            "506:\tlearn: 0.1675508\ttotal: 1m 18s\tremaining: 1m 16s\n",
            "507:\tlearn: 0.1675390\ttotal: 1m 18s\tremaining: 1m 16s\n",
            "508:\tlearn: 0.1675322\ttotal: 1m 18s\tremaining: 1m 15s\n",
            "509:\tlearn: 0.1675200\ttotal: 1m 18s\tremaining: 1m 15s\n",
            "510:\tlearn: 0.1675058\ttotal: 1m 19s\tremaining: 1m 15s\n",
            "511:\tlearn: 0.1674996\ttotal: 1m 19s\tremaining: 1m 15s\n",
            "512:\tlearn: 0.1674921\ttotal: 1m 19s\tremaining: 1m 15s\n",
            "513:\tlearn: 0.1674806\ttotal: 1m 19s\tremaining: 1m 15s\n",
            "514:\tlearn: 0.1674686\ttotal: 1m 19s\tremaining: 1m 14s\n",
            "515:\tlearn: 0.1674595\ttotal: 1m 19s\tremaining: 1m 14s\n",
            "516:\tlearn: 0.1674445\ttotal: 1m 19s\tremaining: 1m 14s\n",
            "517:\tlearn: 0.1674298\ttotal: 1m 20s\tremaining: 1m 14s\n",
            "518:\tlearn: 0.1674113\ttotal: 1m 20s\tremaining: 1m 14s\n",
            "519:\tlearn: 0.1673871\ttotal: 1m 20s\tremaining: 1m 14s\n",
            "520:\tlearn: 0.1673764\ttotal: 1m 20s\tremaining: 1m 14s\n",
            "521:\tlearn: 0.1673708\ttotal: 1m 20s\tremaining: 1m 14s\n",
            "522:\tlearn: 0.1673509\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "523:\tlearn: 0.1673422\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "524:\tlearn: 0.1673324\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "525:\tlearn: 0.1673106\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "526:\tlearn: 0.1672915\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "527:\tlearn: 0.1672826\ttotal: 1m 21s\tremaining: 1m 13s\n",
            "528:\tlearn: 0.1672716\ttotal: 1m 21s\tremaining: 1m 12s\n",
            "529:\tlearn: 0.1672639\ttotal: 1m 21s\tremaining: 1m 12s\n",
            "530:\tlearn: 0.1672535\ttotal: 1m 22s\tremaining: 1m 12s\n",
            "531:\tlearn: 0.1672461\ttotal: 1m 22s\tremaining: 1m 12s\n",
            "532:\tlearn: 0.1672303\ttotal: 1m 22s\tremaining: 1m 12s\n",
            "533:\tlearn: 0.1672200\ttotal: 1m 22s\tremaining: 1m 12s\n",
            "534:\tlearn: 0.1671998\ttotal: 1m 22s\tremaining: 1m 12s\n",
            "535:\tlearn: 0.1671863\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "536:\tlearn: 0.1671775\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "537:\tlearn: 0.1671705\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "538:\tlearn: 0.1671509\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "539:\tlearn: 0.1671395\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "540:\tlearn: 0.1671274\ttotal: 1m 23s\tremaining: 1m 11s\n",
            "541:\tlearn: 0.1671018\ttotal: 1m 23s\tremaining: 1m 10s\n",
            "542:\tlearn: 0.1670840\ttotal: 1m 24s\tremaining: 1m 10s\n",
            "543:\tlearn: 0.1670695\ttotal: 1m 24s\tremaining: 1m 10s\n",
            "544:\tlearn: 0.1670608\ttotal: 1m 24s\tremaining: 1m 10s\n",
            "545:\tlearn: 0.1670544\ttotal: 1m 24s\tremaining: 1m 10s\n",
            "546:\tlearn: 0.1670386\ttotal: 1m 24s\tremaining: 1m 10s\n",
            "547:\tlearn: 0.1670277\ttotal: 1m 24s\tremaining: 1m 9s\n",
            "548:\tlearn: 0.1670171\ttotal: 1m 24s\tremaining: 1m 9s\n",
            "549:\tlearn: 0.1670083\ttotal: 1m 24s\tremaining: 1m 9s\n",
            "550:\tlearn: 0.1669940\ttotal: 1m 25s\tremaining: 1m 9s\n",
            "551:\tlearn: 0.1669739\ttotal: 1m 25s\tremaining: 1m 9s\n",
            "552:\tlearn: 0.1669623\ttotal: 1m 25s\tremaining: 1m 9s\n",
            "553:\tlearn: 0.1669484\ttotal: 1m 25s\tremaining: 1m 9s\n",
            "554:\tlearn: 0.1669383\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "555:\tlearn: 0.1669261\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "556:\tlearn: 0.1669198\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "557:\tlearn: 0.1669043\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "558:\tlearn: 0.1668854\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "559:\tlearn: 0.1668770\ttotal: 1m 26s\tremaining: 1m 8s\n",
            "560:\tlearn: 0.1668661\ttotal: 1m 26s\tremaining: 1m 7s\n",
            "561:\tlearn: 0.1668547\ttotal: 1m 26s\tremaining: 1m 7s\n",
            "562:\tlearn: 0.1668379\ttotal: 1m 27s\tremaining: 1m 7s\n",
            "563:\tlearn: 0.1668183\ttotal: 1m 27s\tremaining: 1m 7s\n",
            "564:\tlearn: 0.1667929\ttotal: 1m 27s\tremaining: 1m 7s\n",
            "565:\tlearn: 0.1667714\ttotal: 1m 27s\tremaining: 1m 7s\n",
            "566:\tlearn: 0.1667586\ttotal: 1m 27s\tremaining: 1m 6s\n",
            "567:\tlearn: 0.1667384\ttotal: 1m 27s\tremaining: 1m 6s\n",
            "568:\tlearn: 0.1667247\ttotal: 1m 28s\tremaining: 1m 6s\n",
            "569:\tlearn: 0.1667174\ttotal: 1m 28s\tremaining: 1m 6s\n",
            "570:\tlearn: 0.1666988\ttotal: 1m 28s\tremaining: 1m 6s\n",
            "571:\tlearn: 0.1666930\ttotal: 1m 28s\tremaining: 1m 6s\n",
            "572:\tlearn: 0.1666538\ttotal: 1m 29s\tremaining: 1m 6s\n",
            "573:\tlearn: 0.1666454\ttotal: 1m 29s\tremaining: 1m 6s\n",
            "574:\tlearn: 0.1666388\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "575:\tlearn: 0.1666353\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "576:\tlearn: 0.1666151\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "577:\tlearn: 0.1666022\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "578:\tlearn: 0.1665957\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "579:\tlearn: 0.1665799\ttotal: 1m 29s\tremaining: 1m 5s\n",
            "580:\tlearn: 0.1665701\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "581:\tlearn: 0.1665501\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "582:\tlearn: 0.1665262\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "583:\tlearn: 0.1665119\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "584:\tlearn: 0.1665016\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "585:\tlearn: 0.1664868\ttotal: 1m 30s\tremaining: 1m 4s\n",
            "586:\tlearn: 0.1664802\ttotal: 1m 31s\tremaining: 1m 4s\n",
            "587:\tlearn: 0.1664691\ttotal: 1m 31s\tremaining: 1m 4s\n",
            "588:\tlearn: 0.1664635\ttotal: 1m 31s\tremaining: 1m 3s\n",
            "589:\tlearn: 0.1664574\ttotal: 1m 31s\tremaining: 1m 3s\n",
            "590:\tlearn: 0.1664383\ttotal: 1m 31s\tremaining: 1m 3s\n",
            "591:\tlearn: 0.1664234\ttotal: 1m 32s\tremaining: 1m 3s\n",
            "592:\tlearn: 0.1664032\ttotal: 1m 32s\tremaining: 1m 3s\n",
            "593:\tlearn: 0.1663944\ttotal: 1m 32s\tremaining: 1m 3s\n",
            "594:\tlearn: 0.1663852\ttotal: 1m 32s\tremaining: 1m 2s\n",
            "595:\tlearn: 0.1663770\ttotal: 1m 32s\tremaining: 1m 2s\n",
            "596:\tlearn: 0.1663678\ttotal: 1m 32s\tremaining: 1m 2s\n",
            "597:\tlearn: 0.1663595\ttotal: 1m 32s\tremaining: 1m 2s\n",
            "598:\tlearn: 0.1663454\ttotal: 1m 33s\tremaining: 1m 2s\n",
            "599:\tlearn: 0.1663324\ttotal: 1m 33s\tremaining: 1m 2s\n",
            "600:\tlearn: 0.1663220\ttotal: 1m 33s\tremaining: 1m 2s\n",
            "601:\tlearn: 0.1663073\ttotal: 1m 33s\tremaining: 1m 1s\n",
            "602:\tlearn: 0.1662938\ttotal: 1m 33s\tremaining: 1m 1s\n",
            "603:\tlearn: 0.1662843\ttotal: 1m 33s\tremaining: 1m 1s\n",
            "604:\tlearn: 0.1662733\ttotal: 1m 34s\tremaining: 1m 1s\n",
            "605:\tlearn: 0.1662614\ttotal: 1m 34s\tremaining: 1m 1s\n",
            "606:\tlearn: 0.1662489\ttotal: 1m 34s\tremaining: 1m 1s\n",
            "607:\tlearn: 0.1662352\ttotal: 1m 34s\tremaining: 1m 1s\n",
            "608:\tlearn: 0.1662243\ttotal: 1m 34s\tremaining: 1m\n",
            "609:\tlearn: 0.1662051\ttotal: 1m 34s\tremaining: 1m\n",
            "610:\tlearn: 0.1661906\ttotal: 1m 35s\tremaining: 1m\n",
            "611:\tlearn: 0.1661752\ttotal: 1m 35s\tremaining: 1m\n",
            "612:\tlearn: 0.1661669\ttotal: 1m 35s\tremaining: 1m\n",
            "613:\tlearn: 0.1661499\ttotal: 1m 35s\tremaining: 1m\n",
            "614:\tlearn: 0.1661346\ttotal: 1m 35s\tremaining: 59.9s\n",
            "615:\tlearn: 0.1661301\ttotal: 1m 35s\tremaining: 59.7s\n",
            "616:\tlearn: 0.1661156\ttotal: 1m 35s\tremaining: 59.5s\n",
            "617:\tlearn: 0.1660938\ttotal: 1m 36s\tremaining: 59.3s\n",
            "618:\tlearn: 0.1660869\ttotal: 1m 36s\tremaining: 59.2s\n",
            "619:\tlearn: 0.1660746\ttotal: 1m 36s\tremaining: 59s\n",
            "620:\tlearn: 0.1660665\ttotal: 1m 36s\tremaining: 58.8s\n",
            "621:\tlearn: 0.1660599\ttotal: 1m 36s\tremaining: 58.6s\n",
            "622:\tlearn: 0.1660485\ttotal: 1m 36s\tremaining: 58.5s\n",
            "623:\tlearn: 0.1660399\ttotal: 1m 36s\tremaining: 58.3s\n",
            "624:\tlearn: 0.1660319\ttotal: 1m 36s\tremaining: 58.2s\n",
            "625:\tlearn: 0.1660180\ttotal: 1m 37s\tremaining: 58s\n",
            "626:\tlearn: 0.1659986\ttotal: 1m 37s\tremaining: 57.9s\n",
            "627:\tlearn: 0.1659870\ttotal: 1m 37s\tremaining: 57.7s\n",
            "628:\tlearn: 0.1659787\ttotal: 1m 37s\tremaining: 57.6s\n",
            "629:\tlearn: 0.1659560\ttotal: 1m 37s\tremaining: 57.4s\n",
            "630:\tlearn: 0.1659441\ttotal: 1m 37s\tremaining: 57.3s\n",
            "631:\tlearn: 0.1659371\ttotal: 1m 37s\tremaining: 57.1s\n",
            "632:\tlearn: 0.1659086\ttotal: 1m 38s\tremaining: 56.9s\n",
            "633:\tlearn: 0.1658939\ttotal: 1m 38s\tremaining: 56.7s\n",
            "634:\tlearn: 0.1658787\ttotal: 1m 38s\tremaining: 56.6s\n",
            "635:\tlearn: 0.1658585\ttotal: 1m 38s\tremaining: 56.4s\n",
            "636:\tlearn: 0.1658452\ttotal: 1m 38s\tremaining: 56.3s\n",
            "637:\tlearn: 0.1658367\ttotal: 1m 38s\tremaining: 56.1s\n",
            "638:\tlearn: 0.1658291\ttotal: 1m 39s\tremaining: 56s\n",
            "639:\tlearn: 0.1658198\ttotal: 1m 39s\tremaining: 55.8s\n",
            "640:\tlearn: 0.1658104\ttotal: 1m 39s\tremaining: 55.6s\n",
            "641:\tlearn: 0.1658013\ttotal: 1m 39s\tremaining: 55.5s\n",
            "642:\tlearn: 0.1657860\ttotal: 1m 39s\tremaining: 55.3s\n",
            "643:\tlearn: 0.1657782\ttotal: 1m 39s\tremaining: 55.1s\n",
            "644:\tlearn: 0.1657700\ttotal: 1m 39s\tremaining: 54.9s\n",
            "645:\tlearn: 0.1657564\ttotal: 1m 40s\tremaining: 54.8s\n",
            "646:\tlearn: 0.1657413\ttotal: 1m 40s\tremaining: 54.8s\n",
            "647:\tlearn: 0.1657255\ttotal: 1m 40s\tremaining: 54.6s\n",
            "648:\tlearn: 0.1657174\ttotal: 1m 40s\tremaining: 54.5s\n",
            "649:\tlearn: 0.1657008\ttotal: 1m 40s\tremaining: 54.4s\n",
            "650:\tlearn: 0.1656943\ttotal: 1m 41s\tremaining: 54.2s\n",
            "651:\tlearn: 0.1656889\ttotal: 1m 41s\tremaining: 54s\n",
            "652:\tlearn: 0.1656786\ttotal: 1m 41s\tremaining: 53.9s\n",
            "653:\tlearn: 0.1656705\ttotal: 1m 41s\tremaining: 53.7s\n",
            "654:\tlearn: 0.1656607\ttotal: 1m 41s\tremaining: 53.6s\n",
            "655:\tlearn: 0.1656514\ttotal: 1m 41s\tremaining: 53.5s\n",
            "656:\tlearn: 0.1656443\ttotal: 1m 42s\tremaining: 53.3s\n",
            "657:\tlearn: 0.1656340\ttotal: 1m 42s\tremaining: 53.1s\n",
            "658:\tlearn: 0.1656246\ttotal: 1m 42s\tremaining: 53s\n",
            "659:\tlearn: 0.1656093\ttotal: 1m 42s\tremaining: 52.9s\n",
            "660:\tlearn: 0.1655980\ttotal: 1m 42s\tremaining: 52.8s\n",
            "661:\tlearn: 0.1655849\ttotal: 1m 43s\tremaining: 52.7s\n",
            "662:\tlearn: 0.1655749\ttotal: 1m 43s\tremaining: 52.5s\n",
            "663:\tlearn: 0.1655647\ttotal: 1m 43s\tremaining: 52.3s\n",
            "664:\tlearn: 0.1655387\ttotal: 1m 43s\tremaining: 52.2s\n",
            "665:\tlearn: 0.1655265\ttotal: 1m 43s\tremaining: 52s\n",
            "666:\tlearn: 0.1655217\ttotal: 1m 43s\tremaining: 51.8s\n",
            "667:\tlearn: 0.1655114\ttotal: 1m 43s\tremaining: 51.7s\n",
            "668:\tlearn: 0.1655001\ttotal: 1m 44s\tremaining: 51.5s\n",
            "669:\tlearn: 0.1654941\ttotal: 1m 44s\tremaining: 51.3s\n",
            "670:\tlearn: 0.1654866\ttotal: 1m 44s\tremaining: 51.2s\n",
            "671:\tlearn: 0.1654779\ttotal: 1m 44s\tremaining: 51s\n",
            "672:\tlearn: 0.1654672\ttotal: 1m 44s\tremaining: 51s\n",
            "673:\tlearn: 0.1654606\ttotal: 1m 45s\tremaining: 50.8s\n",
            "674:\tlearn: 0.1654558\ttotal: 1m 45s\tremaining: 50.7s\n",
            "675:\tlearn: 0.1654464\ttotal: 1m 45s\tremaining: 50.5s\n",
            "676:\tlearn: 0.1654418\ttotal: 1m 45s\tremaining: 50.4s\n",
            "677:\tlearn: 0.1654305\ttotal: 1m 45s\tremaining: 50.2s\n",
            "678:\tlearn: 0.1653846\ttotal: 1m 45s\tremaining: 50s\n",
            "679:\tlearn: 0.1653744\ttotal: 1m 46s\tremaining: 49.9s\n",
            "680:\tlearn: 0.1653696\ttotal: 1m 46s\tremaining: 49.7s\n",
            "681:\tlearn: 0.1653656\ttotal: 1m 46s\tremaining: 49.5s\n",
            "682:\tlearn: 0.1653580\ttotal: 1m 46s\tremaining: 49.4s\n",
            "683:\tlearn: 0.1653491\ttotal: 1m 46s\tremaining: 49.2s\n",
            "684:\tlearn: 0.1653378\ttotal: 1m 46s\tremaining: 49.1s\n",
            "685:\tlearn: 0.1653270\ttotal: 1m 46s\tremaining: 48.9s\n",
            "686:\tlearn: 0.1653166\ttotal: 1m 46s\tremaining: 48.7s\n",
            "687:\tlearn: 0.1653012\ttotal: 1m 47s\tremaining: 48.6s\n",
            "688:\tlearn: 0.1652909\ttotal: 1m 47s\tremaining: 48.5s\n",
            "689:\tlearn: 0.1652830\ttotal: 1m 47s\tremaining: 48.4s\n",
            "690:\tlearn: 0.1652692\ttotal: 1m 47s\tremaining: 48.3s\n",
            "691:\tlearn: 0.1652638\ttotal: 1m 48s\tremaining: 48.1s\n",
            "692:\tlearn: 0.1652433\ttotal: 1m 48s\tremaining: 47.9s\n",
            "693:\tlearn: 0.1652349\ttotal: 1m 48s\tremaining: 47.8s\n",
            "694:\tlearn: 0.1652252\ttotal: 1m 48s\tremaining: 47.6s\n",
            "695:\tlearn: 0.1652185\ttotal: 1m 48s\tremaining: 47.5s\n",
            "696:\tlearn: 0.1652009\ttotal: 1m 48s\tremaining: 47.3s\n",
            "697:\tlearn: 0.1651880\ttotal: 1m 48s\tremaining: 47.1s\n",
            "698:\tlearn: 0.1651658\ttotal: 1m 49s\tremaining: 47s\n",
            "699:\tlearn: 0.1651609\ttotal: 1m 49s\tremaining: 46.8s\n",
            "700:\tlearn: 0.1651550\ttotal: 1m 49s\tremaining: 46.6s\n",
            "701:\tlearn: 0.1651458\ttotal: 1m 49s\tremaining: 46.5s\n",
            "702:\tlearn: 0.1651409\ttotal: 1m 49s\tremaining: 46.3s\n",
            "703:\tlearn: 0.1651338\ttotal: 1m 49s\tremaining: 46.1s\n",
            "704:\tlearn: 0.1651207\ttotal: 1m 49s\tremaining: 46s\n",
            "705:\tlearn: 0.1651109\ttotal: 1m 50s\tremaining: 45.9s\n",
            "706:\tlearn: 0.1650977\ttotal: 1m 50s\tremaining: 45.8s\n",
            "707:\tlearn: 0.1650893\ttotal: 1m 50s\tremaining: 45.7s\n",
            "708:\tlearn: 0.1650783\ttotal: 1m 50s\tremaining: 45.5s\n",
            "709:\tlearn: 0.1650698\ttotal: 1m 51s\tremaining: 45.4s\n",
            "710:\tlearn: 0.1650571\ttotal: 1m 51s\tremaining: 45.2s\n",
            "711:\tlearn: 0.1650507\ttotal: 1m 51s\tremaining: 45s\n",
            "712:\tlearn: 0.1650456\ttotal: 1m 51s\tremaining: 44.9s\n",
            "713:\tlearn: 0.1650399\ttotal: 1m 51s\tremaining: 44.7s\n",
            "714:\tlearn: 0.1650313\ttotal: 1m 51s\tremaining: 44.6s\n",
            "715:\tlearn: 0.1650258\ttotal: 1m 51s\tremaining: 44.4s\n",
            "716:\tlearn: 0.1650206\ttotal: 1m 52s\tremaining: 44.2s\n",
            "717:\tlearn: 0.1650147\ttotal: 1m 52s\tremaining: 44.1s\n",
            "718:\tlearn: 0.1650092\ttotal: 1m 52s\tremaining: 43.9s\n",
            "719:\tlearn: 0.1649986\ttotal: 1m 52s\tremaining: 43.7s\n",
            "720:\tlearn: 0.1649894\ttotal: 1m 52s\tremaining: 43.6s\n",
            "721:\tlearn: 0.1649753\ttotal: 1m 52s\tremaining: 43.4s\n",
            "722:\tlearn: 0.1649692\ttotal: 1m 52s\tremaining: 43.3s\n",
            "723:\tlearn: 0.1649562\ttotal: 1m 53s\tremaining: 43.1s\n",
            "724:\tlearn: 0.1649354\ttotal: 1m 53s\tremaining: 42.9s\n",
            "725:\tlearn: 0.1649217\ttotal: 1m 53s\tremaining: 42.8s\n",
            "726:\tlearn: 0.1649118\ttotal: 1m 53s\tremaining: 42.7s\n",
            "727:\tlearn: 0.1649046\ttotal: 1m 53s\tremaining: 42.6s\n",
            "728:\tlearn: 0.1648928\ttotal: 1m 54s\tremaining: 42.4s\n",
            "729:\tlearn: 0.1648880\ttotal: 1m 54s\tremaining: 42.3s\n",
            "730:\tlearn: 0.1648788\ttotal: 1m 54s\tremaining: 42.1s\n",
            "731:\tlearn: 0.1648641\ttotal: 1m 54s\tremaining: 42s\n",
            "732:\tlearn: 0.1648542\ttotal: 1m 54s\tremaining: 41.8s\n",
            "733:\tlearn: 0.1648502\ttotal: 1m 54s\tremaining: 41.6s\n",
            "734:\tlearn: 0.1648371\ttotal: 1m 54s\tremaining: 41.4s\n",
            "735:\tlearn: 0.1648314\ttotal: 1m 55s\tremaining: 41.3s\n",
            "736:\tlearn: 0.1648192\ttotal: 1m 55s\tremaining: 41.1s\n",
            "737:\tlearn: 0.1648093\ttotal: 1m 55s\tremaining: 41s\n",
            "738:\tlearn: 0.1647987\ttotal: 1m 55s\tremaining: 40.8s\n",
            "739:\tlearn: 0.1647919\ttotal: 1m 55s\tremaining: 40.6s\n",
            "740:\tlearn: 0.1647851\ttotal: 1m 55s\tremaining: 40.5s\n",
            "741:\tlearn: 0.1647794\ttotal: 1m 55s\tremaining: 40.3s\n",
            "742:\tlearn: 0.1647635\ttotal: 1m 56s\tremaining: 40.2s\n",
            "743:\tlearn: 0.1647517\ttotal: 1m 56s\tremaining: 40s\n",
            "744:\tlearn: 0.1647409\ttotal: 1m 56s\tremaining: 39.9s\n",
            "745:\tlearn: 0.1647358\ttotal: 1m 56s\tremaining: 39.8s\n",
            "746:\tlearn: 0.1647250\ttotal: 1m 56s\tremaining: 39.6s\n",
            "747:\tlearn: 0.1647143\ttotal: 1m 57s\tremaining: 39.5s\n",
            "748:\tlearn: 0.1647057\ttotal: 1m 57s\tremaining: 39.3s\n",
            "749:\tlearn: 0.1646975\ttotal: 1m 57s\tremaining: 39.2s\n",
            "750:\tlearn: 0.1646914\ttotal: 1m 57s\tremaining: 39s\n",
            "751:\tlearn: 0.1646828\ttotal: 1m 57s\tremaining: 38.9s\n",
            "752:\tlearn: 0.1646780\ttotal: 1m 57s\tremaining: 38.7s\n",
            "753:\tlearn: 0.1646646\ttotal: 1m 58s\tremaining: 38.5s\n",
            "754:\tlearn: 0.1646537\ttotal: 1m 58s\tremaining: 38.4s\n",
            "755:\tlearn: 0.1646453\ttotal: 1m 58s\tremaining: 38.2s\n",
            "756:\tlearn: 0.1646384\ttotal: 1m 58s\tremaining: 38s\n",
            "757:\tlearn: 0.1646342\ttotal: 1m 58s\tremaining: 37.9s\n",
            "758:\tlearn: 0.1646229\ttotal: 1m 58s\tremaining: 37.7s\n",
            "759:\tlearn: 0.1646165\ttotal: 1m 58s\tremaining: 37.5s\n",
            "760:\tlearn: 0.1646032\ttotal: 1m 58s\tremaining: 37.3s\n",
            "761:\tlearn: 0.1645963\ttotal: 1m 59s\tremaining: 37.2s\n",
            "762:\tlearn: 0.1645866\ttotal: 1m 59s\tremaining: 37s\n",
            "763:\tlearn: 0.1645745\ttotal: 1m 59s\tremaining: 36.8s\n",
            "764:\tlearn: 0.1645666\ttotal: 1m 59s\tremaining: 36.7s\n",
            "765:\tlearn: 0.1645611\ttotal: 1m 59s\tremaining: 36.5s\n",
            "766:\tlearn: 0.1645477\ttotal: 1m 59s\tremaining: 36.4s\n",
            "767:\tlearn: 0.1645393\ttotal: 1m 59s\tremaining: 36.2s\n",
            "768:\tlearn: 0.1645301\ttotal: 2m\tremaining: 36.1s\n",
            "769:\tlearn: 0.1645223\ttotal: 2m\tremaining: 35.9s\n",
            "770:\tlearn: 0.1645143\ttotal: 2m\tremaining: 35.8s\n",
            "771:\tlearn: 0.1645075\ttotal: 2m\tremaining: 35.6s\n",
            "772:\tlearn: 0.1644986\ttotal: 2m\tremaining: 35.5s\n",
            "773:\tlearn: 0.1644943\ttotal: 2m\tremaining: 35.3s\n",
            "774:\tlearn: 0.1644879\ttotal: 2m 1s\tremaining: 35.2s\n",
            "775:\tlearn: 0.1644788\ttotal: 2m 1s\tremaining: 35s\n",
            "776:\tlearn: 0.1644683\ttotal: 2m 1s\tremaining: 34.8s\n",
            "777:\tlearn: 0.1644532\ttotal: 2m 1s\tremaining: 34.7s\n",
            "778:\tlearn: 0.1644454\ttotal: 2m 1s\tremaining: 34.5s\n",
            "779:\tlearn: 0.1644268\ttotal: 2m 1s\tremaining: 34.3s\n",
            "780:\tlearn: 0.1644174\ttotal: 2m 1s\tremaining: 34.2s\n",
            "781:\tlearn: 0.1644063\ttotal: 2m 1s\tremaining: 34s\n",
            "782:\tlearn: 0.1643926\ttotal: 2m 2s\tremaining: 33.8s\n",
            "783:\tlearn: 0.1643785\ttotal: 2m 2s\tremaining: 33.7s\n",
            "784:\tlearn: 0.1643685\ttotal: 2m 2s\tremaining: 33.5s\n",
            "785:\tlearn: 0.1643556\ttotal: 2m 2s\tremaining: 33.3s\n",
            "786:\tlearn: 0.1643396\ttotal: 2m 2s\tremaining: 33.2s\n",
            "787:\tlearn: 0.1643271\ttotal: 2m 3s\tremaining: 33.1s\n",
            "788:\tlearn: 0.1643231\ttotal: 2m 3s\tremaining: 33s\n",
            "789:\tlearn: 0.1643154\ttotal: 2m 3s\tremaining: 32.8s\n",
            "790:\tlearn: 0.1643018\ttotal: 2m 3s\tremaining: 32.7s\n",
            "791:\tlearn: 0.1642915\ttotal: 2m 3s\tremaining: 32.5s\n",
            "792:\tlearn: 0.1642852\ttotal: 2m 3s\tremaining: 32.3s\n",
            "793:\tlearn: 0.1642798\ttotal: 2m 4s\tremaining: 32.2s\n",
            "794:\tlearn: 0.1642614\ttotal: 2m 4s\tremaining: 32s\n",
            "795:\tlearn: 0.1642497\ttotal: 2m 4s\tremaining: 31.9s\n",
            "796:\tlearn: 0.1642412\ttotal: 2m 4s\tremaining: 31.7s\n",
            "797:\tlearn: 0.1642302\ttotal: 2m 4s\tremaining: 31.5s\n",
            "798:\tlearn: 0.1642268\ttotal: 2m 4s\tremaining: 31.4s\n",
            "799:\tlearn: 0.1642185\ttotal: 2m 4s\tremaining: 31.2s\n",
            "800:\tlearn: 0.1642090\ttotal: 2m 4s\tremaining: 31s\n",
            "801:\tlearn: 0.1642006\ttotal: 2m 5s\tremaining: 30.9s\n",
            "802:\tlearn: 0.1641820\ttotal: 2m 5s\tremaining: 30.7s\n",
            "803:\tlearn: 0.1641740\ttotal: 2m 5s\tremaining: 30.6s\n",
            "804:\tlearn: 0.1641654\ttotal: 2m 5s\tremaining: 30.4s\n",
            "805:\tlearn: 0.1641474\ttotal: 2m 5s\tremaining: 30.3s\n",
            "806:\tlearn: 0.1641337\ttotal: 2m 6s\tremaining: 30.2s\n",
            "807:\tlearn: 0.1641217\ttotal: 2m 6s\tremaining: 30s\n",
            "808:\tlearn: 0.1641147\ttotal: 2m 6s\tremaining: 29.9s\n",
            "809:\tlearn: 0.1641065\ttotal: 2m 6s\tremaining: 29.7s\n",
            "810:\tlearn: 0.1640943\ttotal: 2m 6s\tremaining: 29.5s\n",
            "811:\tlearn: 0.1640868\ttotal: 2m 6s\tremaining: 29.4s\n",
            "812:\tlearn: 0.1640809\ttotal: 2m 7s\tremaining: 29.2s\n",
            "813:\tlearn: 0.1640713\ttotal: 2m 7s\tremaining: 29.1s\n",
            "814:\tlearn: 0.1640654\ttotal: 2m 7s\tremaining: 28.9s\n",
            "815:\tlearn: 0.1640628\ttotal: 2m 7s\tremaining: 28.8s\n",
            "816:\tlearn: 0.1640529\ttotal: 2m 7s\tremaining: 28.6s\n",
            "817:\tlearn: 0.1640424\ttotal: 2m 7s\tremaining: 28.5s\n",
            "818:\tlearn: 0.1640352\ttotal: 2m 8s\tremaining: 28.3s\n",
            "819:\tlearn: 0.1640286\ttotal: 2m 8s\tremaining: 28.2s\n",
            "820:\tlearn: 0.1640227\ttotal: 2m 8s\tremaining: 28s\n",
            "821:\tlearn: 0.1640187\ttotal: 2m 8s\tremaining: 27.9s\n",
            "822:\tlearn: 0.1640080\ttotal: 2m 8s\tremaining: 27.7s\n",
            "823:\tlearn: 0.1640014\ttotal: 2m 9s\tremaining: 27.6s\n",
            "824:\tlearn: 0.1639861\ttotal: 2m 9s\tremaining: 27.4s\n",
            "825:\tlearn: 0.1639751\ttotal: 2m 9s\tremaining: 27.2s\n",
            "826:\tlearn: 0.1639704\ttotal: 2m 9s\tremaining: 27.1s\n",
            "827:\tlearn: 0.1639601\ttotal: 2m 9s\tremaining: 26.9s\n",
            "828:\tlearn: 0.1639519\ttotal: 2m 9s\tremaining: 26.8s\n",
            "829:\tlearn: 0.1639416\ttotal: 2m 10s\tremaining: 26.7s\n",
            "830:\tlearn: 0.1639345\ttotal: 2m 10s\tremaining: 26.5s\n",
            "831:\tlearn: 0.1639287\ttotal: 2m 10s\tremaining: 26.4s\n",
            "832:\tlearn: 0.1639269\ttotal: 2m 10s\tremaining: 26.2s\n",
            "833:\tlearn: 0.1639218\ttotal: 2m 11s\tremaining: 26.1s\n",
            "834:\tlearn: 0.1639123\ttotal: 2m 11s\tremaining: 25.9s\n",
            "835:\tlearn: 0.1639037\ttotal: 2m 11s\tremaining: 25.8s\n",
            "836:\tlearn: 0.1639016\ttotal: 2m 11s\tremaining: 25.6s\n",
            "837:\tlearn: 0.1638947\ttotal: 2m 11s\tremaining: 25.5s\n",
            "838:\tlearn: 0.1638792\ttotal: 2m 11s\tremaining: 25.3s\n",
            "839:\tlearn: 0.1638696\ttotal: 2m 12s\tremaining: 25.2s\n",
            "840:\tlearn: 0.1638576\ttotal: 2m 12s\tremaining: 25s\n",
            "841:\tlearn: 0.1638496\ttotal: 2m 12s\tremaining: 24.8s\n",
            "842:\tlearn: 0.1638438\ttotal: 2m 12s\tremaining: 24.7s\n",
            "843:\tlearn: 0.1638395\ttotal: 2m 12s\tremaining: 24.5s\n",
            "844:\tlearn: 0.1638287\ttotal: 2m 12s\tremaining: 24.3s\n",
            "845:\tlearn: 0.1638219\ttotal: 2m 12s\tremaining: 24.2s\n",
            "846:\tlearn: 0.1638161\ttotal: 2m 13s\tremaining: 24s\n",
            "847:\tlearn: 0.1638072\ttotal: 2m 13s\tremaining: 23.9s\n",
            "848:\tlearn: 0.1637939\ttotal: 2m 13s\tremaining: 23.7s\n",
            "849:\tlearn: 0.1637774\ttotal: 2m 13s\tremaining: 23.6s\n",
            "850:\tlearn: 0.1637694\ttotal: 2m 13s\tremaining: 23.4s\n",
            "851:\tlearn: 0.1637602\ttotal: 2m 14s\tremaining: 23.3s\n",
            "852:\tlearn: 0.1637524\ttotal: 2m 14s\tremaining: 23.1s\n",
            "853:\tlearn: 0.1637381\ttotal: 2m 14s\tremaining: 23s\n",
            "854:\tlearn: 0.1637336\ttotal: 2m 14s\tremaining: 22.8s\n",
            "855:\tlearn: 0.1637256\ttotal: 2m 14s\tremaining: 22.7s\n",
            "856:\tlearn: 0.1637225\ttotal: 2m 14s\tremaining: 22.5s\n",
            "857:\tlearn: 0.1637125\ttotal: 2m 15s\tremaining: 22.3s\n",
            "858:\tlearn: 0.1637101\ttotal: 2m 15s\tremaining: 22.2s\n",
            "859:\tlearn: 0.1637008\ttotal: 2m 15s\tremaining: 22s\n",
            "860:\tlearn: 0.1636887\ttotal: 2m 15s\tremaining: 21.9s\n",
            "861:\tlearn: 0.1636797\ttotal: 2m 15s\tremaining: 21.7s\n",
            "862:\tlearn: 0.1636720\ttotal: 2m 15s\tremaining: 21.5s\n",
            "863:\tlearn: 0.1636641\ttotal: 2m 15s\tremaining: 21.4s\n",
            "864:\tlearn: 0.1636596\ttotal: 2m 16s\tremaining: 21.2s\n",
            "865:\tlearn: 0.1636516\ttotal: 2m 16s\tremaining: 21.1s\n",
            "866:\tlearn: 0.1636445\ttotal: 2m 16s\tremaining: 20.9s\n",
            "867:\tlearn: 0.1636348\ttotal: 2m 16s\tremaining: 20.8s\n",
            "868:\tlearn: 0.1636301\ttotal: 2m 16s\tremaining: 20.6s\n",
            "869:\tlearn: 0.1636176\ttotal: 2m 17s\tremaining: 20.5s\n",
            "870:\tlearn: 0.1636078\ttotal: 2m 17s\tremaining: 20.4s\n",
            "871:\tlearn: 0.1635972\ttotal: 2m 17s\tremaining: 20.2s\n",
            "872:\tlearn: 0.1635877\ttotal: 2m 17s\tremaining: 20s\n",
            "873:\tlearn: 0.1635778\ttotal: 2m 17s\tremaining: 19.9s\n",
            "874:\tlearn: 0.1635706\ttotal: 2m 18s\tremaining: 19.7s\n",
            "875:\tlearn: 0.1635672\ttotal: 2m 18s\tremaining: 19.6s\n",
            "876:\tlearn: 0.1635585\ttotal: 2m 18s\tremaining: 19.4s\n",
            "877:\tlearn: 0.1635476\ttotal: 2m 18s\tremaining: 19.2s\n",
            "878:\tlearn: 0.1635429\ttotal: 2m 18s\tremaining: 19.1s\n",
            "879:\tlearn: 0.1635340\ttotal: 2m 18s\tremaining: 18.9s\n",
            "880:\tlearn: 0.1635250\ttotal: 2m 18s\tremaining: 18.8s\n",
            "881:\tlearn: 0.1635152\ttotal: 2m 19s\tremaining: 18.6s\n",
            "882:\tlearn: 0.1635030\ttotal: 2m 19s\tremaining: 18.4s\n",
            "883:\tlearn: 0.1634914\ttotal: 2m 19s\tremaining: 18.3s\n",
            "884:\tlearn: 0.1634877\ttotal: 2m 19s\tremaining: 18.1s\n",
            "885:\tlearn: 0.1634776\ttotal: 2m 19s\tremaining: 18s\n",
            "886:\tlearn: 0.1634737\ttotal: 2m 20s\tremaining: 17.9s\n",
            "887:\tlearn: 0.1634647\ttotal: 2m 20s\tremaining: 17.7s\n",
            "888:\tlearn: 0.1634599\ttotal: 2m 20s\tremaining: 17.6s\n",
            "889:\tlearn: 0.1634540\ttotal: 2m 20s\tremaining: 17.4s\n",
            "890:\tlearn: 0.1634470\ttotal: 2m 21s\tremaining: 17.3s\n",
            "891:\tlearn: 0.1634375\ttotal: 2m 21s\tremaining: 17.1s\n",
            "892:\tlearn: 0.1634288\ttotal: 2m 21s\tremaining: 17s\n",
            "893:\tlearn: 0.1634155\ttotal: 2m 21s\tremaining: 16.8s\n",
            "894:\tlearn: 0.1634105\ttotal: 2m 21s\tremaining: 16.6s\n",
            "895:\tlearn: 0.1633970\ttotal: 2m 21s\tremaining: 16.5s\n",
            "896:\tlearn: 0.1633936\ttotal: 2m 22s\tremaining: 16.3s\n",
            "897:\tlearn: 0.1633853\ttotal: 2m 22s\tremaining: 16.2s\n",
            "898:\tlearn: 0.1633764\ttotal: 2m 22s\tremaining: 16s\n",
            "899:\tlearn: 0.1633683\ttotal: 2m 22s\tremaining: 15.8s\n",
            "900:\tlearn: 0.1633616\ttotal: 2m 22s\tremaining: 15.7s\n",
            "901:\tlearn: 0.1633551\ttotal: 2m 22s\tremaining: 15.5s\n",
            "902:\tlearn: 0.1633488\ttotal: 2m 23s\tremaining: 15.4s\n",
            "903:\tlearn: 0.1633349\ttotal: 2m 23s\tremaining: 15.2s\n",
            "904:\tlearn: 0.1633276\ttotal: 2m 23s\tremaining: 15.1s\n",
            "905:\tlearn: 0.1633230\ttotal: 2m 23s\tremaining: 14.9s\n",
            "906:\tlearn: 0.1633171\ttotal: 2m 24s\tremaining: 14.8s\n",
            "907:\tlearn: 0.1633120\ttotal: 2m 24s\tremaining: 14.6s\n",
            "908:\tlearn: 0.1633063\ttotal: 2m 24s\tremaining: 14.5s\n",
            "909:\tlearn: 0.1633048\ttotal: 2m 24s\tremaining: 14.3s\n",
            "910:\tlearn: 0.1632976\ttotal: 2m 24s\tremaining: 14.1s\n",
            "911:\tlearn: 0.1632889\ttotal: 2m 24s\tremaining: 14s\n",
            "912:\tlearn: 0.1632755\ttotal: 2m 24s\tremaining: 13.8s\n",
            "913:\tlearn: 0.1632731\ttotal: 2m 25s\tremaining: 13.6s\n",
            "914:\tlearn: 0.1632637\ttotal: 2m 25s\tremaining: 13.5s\n",
            "915:\tlearn: 0.1632574\ttotal: 2m 25s\tremaining: 13.3s\n",
            "916:\tlearn: 0.1632471\ttotal: 2m 25s\tremaining: 13.2s\n",
            "917:\tlearn: 0.1632343\ttotal: 2m 25s\tremaining: 13s\n",
            "918:\tlearn: 0.1632262\ttotal: 2m 26s\tremaining: 12.9s\n",
            "919:\tlearn: 0.1632187\ttotal: 2m 26s\tremaining: 12.7s\n",
            "920:\tlearn: 0.1632078\ttotal: 2m 26s\tremaining: 12.6s\n",
            "921:\tlearn: 0.1632002\ttotal: 2m 26s\tremaining: 12.4s\n",
            "922:\tlearn: 0.1631910\ttotal: 2m 26s\tremaining: 12.3s\n",
            "923:\tlearn: 0.1631849\ttotal: 2m 27s\tremaining: 12.1s\n",
            "924:\tlearn: 0.1631766\ttotal: 2m 27s\tremaining: 11.9s\n",
            "925:\tlearn: 0.1631729\ttotal: 2m 27s\tremaining: 11.8s\n",
            "926:\tlearn: 0.1631665\ttotal: 2m 27s\tremaining: 11.6s\n",
            "927:\tlearn: 0.1631558\ttotal: 2m 27s\tremaining: 11.5s\n",
            "928:\tlearn: 0.1631388\ttotal: 2m 27s\tremaining: 11.3s\n",
            "929:\tlearn: 0.1631325\ttotal: 2m 27s\tremaining: 11.1s\n",
            "930:\tlearn: 0.1631305\ttotal: 2m 28s\tremaining: 11s\n",
            "931:\tlearn: 0.1631196\ttotal: 2m 28s\tremaining: 10.8s\n",
            "932:\tlearn: 0.1631114\ttotal: 2m 28s\tremaining: 10.7s\n",
            "933:\tlearn: 0.1631063\ttotal: 2m 28s\tremaining: 10.5s\n",
            "934:\tlearn: 0.1630993\ttotal: 2m 28s\tremaining: 10.3s\n",
            "935:\tlearn: 0.1630922\ttotal: 2m 28s\tremaining: 10.2s\n",
            "936:\tlearn: 0.1630825\ttotal: 2m 28s\tremaining: 10s\n",
            "937:\tlearn: 0.1630750\ttotal: 2m 29s\tremaining: 9.86s\n",
            "938:\tlearn: 0.1630712\ttotal: 2m 29s\tremaining: 9.7s\n",
            "939:\tlearn: 0.1630629\ttotal: 2m 29s\tremaining: 9.54s\n",
            "940:\tlearn: 0.1630549\ttotal: 2m 29s\tremaining: 9.38s\n",
            "941:\tlearn: 0.1630410\ttotal: 2m 29s\tremaining: 9.22s\n",
            "942:\tlearn: 0.1630323\ttotal: 2m 30s\tremaining: 9.07s\n",
            "943:\tlearn: 0.1630225\ttotal: 2m 30s\tremaining: 8.92s\n",
            "944:\tlearn: 0.1630184\ttotal: 2m 30s\tremaining: 8.77s\n",
            "945:\tlearn: 0.1630152\ttotal: 2m 30s\tremaining: 8.61s\n",
            "946:\tlearn: 0.1630023\ttotal: 2m 31s\tremaining: 8.46s\n",
            "947:\tlearn: 0.1629986\ttotal: 2m 31s\tremaining: 8.3s\n",
            "948:\tlearn: 0.1629917\ttotal: 2m 31s\tremaining: 8.14s\n",
            "949:\tlearn: 0.1629853\ttotal: 2m 31s\tremaining: 7.97s\n",
            "950:\tlearn: 0.1629731\ttotal: 2m 31s\tremaining: 7.81s\n",
            "951:\tlearn: 0.1629666\ttotal: 2m 31s\tremaining: 7.65s\n",
            "952:\tlearn: 0.1629566\ttotal: 2m 31s\tremaining: 7.49s\n",
            "953:\tlearn: 0.1629516\ttotal: 2m 31s\tremaining: 7.33s\n",
            "954:\tlearn: 0.1629433\ttotal: 2m 32s\tremaining: 7.17s\n",
            "955:\tlearn: 0.1629387\ttotal: 2m 32s\tremaining: 7s\n",
            "956:\tlearn: 0.1629285\ttotal: 2m 32s\tremaining: 6.84s\n",
            "957:\tlearn: 0.1629255\ttotal: 2m 32s\tremaining: 6.68s\n",
            "958:\tlearn: 0.1629117\ttotal: 2m 32s\tremaining: 6.52s\n",
            "959:\tlearn: 0.1629033\ttotal: 2m 32s\tremaining: 6.36s\n",
            "960:\tlearn: 0.1628986\ttotal: 2m 32s\tremaining: 6.2s\n",
            "961:\tlearn: 0.1628878\ttotal: 2m 32s\tremaining: 6.04s\n",
            "962:\tlearn: 0.1628802\ttotal: 2m 32s\tremaining: 5.88s\n",
            "963:\tlearn: 0.1628677\ttotal: 2m 33s\tremaining: 5.72s\n",
            "964:\tlearn: 0.1628615\ttotal: 2m 33s\tremaining: 5.57s\n",
            "965:\tlearn: 0.1628566\ttotal: 2m 33s\tremaining: 5.41s\n",
            "966:\tlearn: 0.1628493\ttotal: 2m 34s\tremaining: 5.26s\n",
            "967:\tlearn: 0.1628431\ttotal: 2m 34s\tremaining: 5.1s\n",
            "968:\tlearn: 0.1628350\ttotal: 2m 34s\tremaining: 4.94s\n",
            "969:\tlearn: 0.1628290\ttotal: 2m 34s\tremaining: 4.78s\n",
            "970:\tlearn: 0.1628277\ttotal: 2m 34s\tremaining: 4.62s\n",
            "971:\tlearn: 0.1628194\ttotal: 2m 34s\tremaining: 4.46s\n",
            "972:\tlearn: 0.1628147\ttotal: 2m 34s\tremaining: 4.3s\n",
            "973:\tlearn: 0.1628081\ttotal: 2m 34s\tremaining: 4.14s\n",
            "974:\tlearn: 0.1628026\ttotal: 2m 35s\tremaining: 3.98s\n",
            "975:\tlearn: 0.1627966\ttotal: 2m 35s\tremaining: 3.82s\n",
            "976:\tlearn: 0.1627911\ttotal: 2m 35s\tremaining: 3.66s\n",
            "977:\tlearn: 0.1627845\ttotal: 2m 35s\tremaining: 3.5s\n",
            "978:\tlearn: 0.1627797\ttotal: 2m 35s\tremaining: 3.34s\n",
            "979:\tlearn: 0.1627762\ttotal: 2m 35s\tremaining: 3.18s\n",
            "980:\tlearn: 0.1627622\ttotal: 2m 35s\tremaining: 3.02s\n",
            "981:\tlearn: 0.1627518\ttotal: 2m 36s\tremaining: 2.86s\n",
            "982:\tlearn: 0.1627453\ttotal: 2m 36s\tremaining: 2.7s\n",
            "983:\tlearn: 0.1627354\ttotal: 2m 36s\tremaining: 2.54s\n",
            "984:\tlearn: 0.1627291\ttotal: 2m 36s\tremaining: 2.38s\n",
            "985:\tlearn: 0.1627217\ttotal: 2m 36s\tremaining: 2.23s\n",
            "986:\tlearn: 0.1627137\ttotal: 2m 36s\tremaining: 2.06s\n",
            "987:\tlearn: 0.1627010\ttotal: 2m 37s\tremaining: 1.91s\n",
            "988:\tlearn: 0.1626958\ttotal: 2m 37s\tremaining: 1.75s\n",
            "989:\tlearn: 0.1626871\ttotal: 2m 37s\tremaining: 1.59s\n",
            "990:\tlearn: 0.1626792\ttotal: 2m 37s\tremaining: 1.43s\n",
            "991:\tlearn: 0.1626706\ttotal: 2m 37s\tremaining: 1.27s\n",
            "992:\tlearn: 0.1626671\ttotal: 2m 38s\tremaining: 1.11s\n",
            "993:\tlearn: 0.1626594\ttotal: 2m 38s\tremaining: 957ms\n",
            "994:\tlearn: 0.1626562\ttotal: 2m 38s\tremaining: 797ms\n",
            "995:\tlearn: 0.1626470\ttotal: 2m 38s\tremaining: 638ms\n",
            "996:\tlearn: 0.1626390\ttotal: 2m 38s\tremaining: 478ms\n",
            "997:\tlearn: 0.1626251\ttotal: 2m 39s\tremaining: 319ms\n",
            "998:\tlearn: 0.1626187\ttotal: 2m 39s\tremaining: 159ms\n",
            "999:\tlearn: 0.1626119\ttotal: 2m 39s\tremaining: 0us\n",
            "Score du modèle (train) : 0.9391311591584263\n",
            "Score du modèle (test) : 0.9374484495864821\n",
            "Métrique pour le modèle XGBClassifier\n",
            "Score d'accuracy 0.9374484495864821\n",
            "Score du recall :  0.7946179233307946\n",
            "Score de la precision :  0.8404940923737916\n",
            "Score F1 :  0.8169124363826177\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     36981\n",
            "           1       0.84      0.79      0.82      7878\n",
            "\n",
            "    accuracy                           0.94     44859\n",
            "   macro avg       0.90      0.88      0.89     44859\n",
            "weighted avg       0.94      0.94      0.94     44859\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'if_binary'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy = 'mean')),\n",
        "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', cat_transformer, cat_col),\n",
        "        ('num', num_transformer, num_col)\n",
        "    ])\n",
        "\n",
        "# Création du pipeline : prétraitement + modèle CatBoost\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', CatBoostClassifier(random_state=42))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# performance du modèle\n",
        "score_tr = pipeline.score(X_train, y_train)\n",
        "score_te = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"Score du modèle (train) :\", score_tr)\n",
        "print(\"Score du modèle (test) :\", score_te)\n",
        "\n",
        "#matrice confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Métrique pour le modèle XGBClassifier\")\n",
        "print(\"Score d'accuracy\", accuracy_score(y_test, y_pred))\n",
        "print(\"Score du recall : \", recall_score(y_test, y_pred))\n",
        "print(\"Score de la precision : \", precision_score(y_test, y_pred))\n",
        "print(\"Score F1 : \", f1_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stacking/Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sauvegarder le modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparamétres du modéle\n",
        "\n",
        "* Random Forest\n",
        "     - max_depth\n",
        "     - min_sample_split\n",
        "     - max_leaf_nodes\n",
        "     - min_samples_leaf\n",
        "     - n_estimators\n",
        "     - max_sample (bootstrap sample)\n",
        "     - max_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour sauvegarder le pipeline dans un fichier pickle après l'avoir entraîné et évalué, il faut suivre les étapes suivantes :\n",
        "\n",
        "    Importer le module pickle.\n",
        "\n",
        "    Utiliser la fonction dump de pickle pour enregistrer votre pipeline dans un fichier pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "#enregistrer le modéle ici 'pipeline' dans un fichier pickle\n",
        "\n",
        "with open('pipeline_rf.pickle', 'wb') as f:\n",
        "    pickle.dump(pipeline, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'mon fichier'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
